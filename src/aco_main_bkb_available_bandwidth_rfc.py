import csv
import random

import networkx as nx  # type: ignore[import-untyped]

from bandwidth_fluctuation_config import (
    BANDWIDTH_UPDATE_INTERVAL,
    initialize_ar1_states,
    print_fluctuation_settings,
    select_fluctuating_edges,
    update_available_bandwidth_ar1,
)
from bkb_learning import (
    BKBLearningConfig,
    calculate_confidence,
    evaporate_bkb_values,  # â˜…BKBæ®ç™ºå‡¦ç†ã‚’è¿½åŠ â˜…
    initialize_graph_nodes_for_bkb,
    update_node_bkb_multi_scale_max,  # â˜…è¤‡æ•°ã‚¹ã‚±ãƒ¼ãƒ«å­¦ç¿’ã‚’è¿½åŠ â˜…
    update_node_bkb_statistics,
    update_node_bkb_three_phase,  # â˜…ä¸‰æ®µéšå­¦ç¿’ã‚’è¿½åŠ â˜…
    update_node_bkb_time_window_max,  # â˜…æ™‚é–“åŒºé–“ãƒ™ãƒ¼ã‚¹å­¦ç¿’ã‚’è¿½åŠ â˜…
)
from modified_dijkstra import max_load_path
from pheromone_update import (
    calculate_current_optimal_bottleneck,
    update_pheromone,
    volatilize_by_width,
)

# ===== ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ =====
V = 0.98  # ãƒ•ã‚§ãƒ­ãƒ¢ãƒ³æ®ç™ºé‡
MIN_F = 100  # ãƒ•ã‚§ãƒ­ãƒ¢ãƒ³æœ€å°å€¤
MAX_F = 1000000000  # ãƒ•ã‚§ãƒ­ãƒ¢ãƒ³æœ€å¤§å€¤
TTL = 100  # Antã®Time to Live

# ===== ACOãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ =====
ALPHA = 1.0  # ãƒ•ã‚§ãƒ­ãƒ¢ãƒ³ã®å½±éŸ¿åº¦
BETA = 1.0  # ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯æƒ…å ±(å¸¯åŸŸå¹…)ã®å½±éŸ¿åº¦
EPSILON = 0.1  # ãƒ©ãƒ³ãƒ€ãƒ ã«è¡Œå‹•ã™ã‚‹å›ºå®šç¢ºç‡
ANT_NUM = 10  # ä¸–ä»£ã”ã¨ã«æ¢ç´¢ã™ã‚‹ã‚¢ãƒªã®æ•°
GENERATION = 1000  # ç·ä¸–ä»£æ•°
SIMULATIONS = 100  # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®è©¦è¡Œå›æ•°

# ===== BKBçµ±è¨ˆãƒ¢ãƒ‡ãƒ«ï¼ˆRFC 6298 æº–æ‹ ï¼‰=====
# ã€è¤‡æ•°ã®å­¦ç¿’é€Ÿåº¦è¨­å®šã€‘
# å‹•çš„ç’°å¢ƒã®å¤‰å‹•é€Ÿåº¦ã«å¿œã˜ã¦é¸æŠ

# --- æ¨™æº–è¨­å®šï¼ˆRFC 6298æº–æ‹ ï¼‰---
BKB_CONFIG_STANDARD = BKBLearningConfig(
    mean_alpha=1 / 8,  # æ¨™æº– SRTT å­¦ç¿’ç‡ (0.125)
    var_beta=1 / 4,  # æ¨™æº– RTTVAR å­¦ç¿’ç‡ (0.25)
    confidence_k=1.0,  # ä¿¡é ¼åŒºé–“å¹…ã®ä¿‚æ•°
    achievement_bonus_base=1.5,  # ã‚·ãƒ³ãƒ—ãƒ«ãªå›ºå®šãƒœãƒ¼ãƒŠã‚¹ä¿‚æ•°
    achievement_bonus_max=3.0,  # ï¼ˆæœªä½¿ç”¨ï¼‰
    confidence_scaling=2.0,  # ï¼ˆæœªä½¿ç”¨ï¼‰
    penalty_factor=0.5,  # ãƒšãƒŠãƒ«ãƒ†ã‚£ä¿‚æ•°
    use_confidence_based_bonus=False,
)

# --- â˜…é«˜é€Ÿå­¦ç¿’è¨­å®šï¼ˆæ¨™æº–ã®2å€é€Ÿï¼‰â˜… ---
BKB_CONFIG_FAST = BKBLearningConfig(
    mean_alpha=1 / 4,  # 2å€é€Ÿ SRTT å­¦ç¿’ç‡ (0.25)
    var_beta=1 / 2,  # 2å€é€Ÿ RTTVAR å­¦ç¿’ç‡ (0.5)
    confidence_k=1.0,  # ï¼ˆå¤‰æ›´ãªã—ï¼‰
    achievement_bonus_base=1.5,  # ï¼ˆå¤‰æ›´ãªã—ï¼‰
    achievement_bonus_max=3.0,  # ï¼ˆæœªä½¿ç”¨ï¼‰
    confidence_scaling=2.0,  # ï¼ˆæœªä½¿ç”¨ï¼‰
    penalty_factor=0.5,  # ï¼ˆå¤‰æ›´ãªã—ï¼‰
    use_confidence_based_bonus=False,
)

# --- è¶…é«˜é€Ÿå­¦ç¿’è¨­å®šï¼ˆæ¨™æº–ã®4å€é€Ÿï¼‰---
BKB_CONFIG_VERY_FAST = BKBLearningConfig(
    mean_alpha=1 / 2,  # 4å€é€Ÿ SRTT å­¦ç¿’ç‡ (0.5)
    var_beta=3 / 4,  # 4å€é€Ÿ RTTVAR å­¦ç¿’ç‡ (0.75)
    confidence_k=1.0,  # ï¼ˆå¤‰æ›´ãªã—ï¼‰
    achievement_bonus_base=2.0,  # â˜…ã‚ˆã‚Šç©æ¥µçš„ãªãƒœãƒ¼ãƒŠã‚¹â˜…
    achievement_bonus_max=3.0,  # ï¼ˆæœªä½¿ç”¨ï¼‰
    confidence_scaling=2.0,  # ï¼ˆæœªä½¿ç”¨ï¼‰
    penalty_factor=0.3,  # â˜…ã‚ˆã‚Šå³ã—ã„ãƒšãƒŠãƒ«ãƒ†ã‚£â˜…
    use_confidence_based_bonus=False,
)

# --- å³æ™‚è¿½å¾“è¨­å®šï¼ˆ8å€é€Ÿï¼šã»ã¼æœ€æ–°å€¤ã‚’ä½¿ç”¨ï¼‰---
BKB_CONFIG_INSTANT = BKBLearningConfig(
    mean_alpha=1.0,  # å³æ™‚è¿½å¾“ï¼ˆå®Œå…¨ã«æœ€æ–°å€¤ï¼‰
    var_beta=1.0,  # å³æ™‚è¿½å¾“ï¼ˆå®Œå…¨ã«æœ€æ–°å€¤ï¼‰
    confidence_k=1.0,  # ï¼ˆå¤‰æ›´ãªã—ï¼‰
    achievement_bonus_base=1.5,  # ï¼ˆå¤‰æ›´ãªã—ï¼‰
    achievement_bonus_max=3.0,  # ï¼ˆæœªä½¿ç”¨ï¼‰
    confidence_scaling=2.0,  # ï¼ˆæœªä½¿ç”¨ï¼‰
    penalty_factor=0.5,  # ï¼ˆå¤‰æ›´ãªã—ï¼‰
    use_confidence_based_bonus=False,
)

# ===== ğŸ¯ ä½¿ç”¨ã™ã‚‹è¨­å®šã‚’é¸æŠ =====
# BKB_CONFIG = BKB_CONFIG_FAST  # é«˜é€Ÿå­¦ç¿’è¨­å®šï¼ˆ2å€é€Ÿï¼‰
# BKB_CONFIG = BKB_CONFIG_STANDARD  # æ¨™æº–è¨­å®š
BKB_CONFIG = BKB_CONFIG_VERY_FAST  # â˜…è¶…é«˜é€Ÿè¨­å®šï¼ˆé«˜å¤‰å‹•ç’°å¢ƒå‘ã‘ï¼‰â˜…
# BKB_CONFIG = BKB_CONFIG_INSTANT  # å³æ™‚è¿½å¾“ï¼ˆå®Ÿé¨“ç”¨ï¼‰

# ===== å­¦ç¿’æ‰‹æ³•ã®é¸æŠ =====
USE_THREE_PHASE_LEARNING = False  # ä¸‰æ®µéšå­¦ç¿’ï¼ˆè¶…çŸ­æœŸ+çŸ­æœŸ+é•·æœŸï¼‰
USE_TWO_PHASE_LEARNING = False  # äºŒæ®µéšå­¦ç¿’ï¼ˆçŸ­æœŸ+é•·æœŸï¼‰
USE_TIME_WINDOW_LEARNING = True  # â˜…æ™‚é–“åŒºé–“ãƒ™ãƒ¼ã‚¹å­¦ç¿’ã‚’ä½¿ç”¨â˜…
USE_MULTI_SCALE_LEARNING = False  # è¤‡æ•°ã‚¹ã‚±ãƒ¼ãƒ«å­¦ç¿’ï¼ˆçŸ­æœŸ+ä¸­æœŸ+é•·æœŸï¼‰
# USE_TWO_PHASE_LEARNING = False  # å¾“æ¥ã®å˜ä¸€EMAå­¦ç¿’

# ===== ãƒªãƒ³ã‚°ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚ºè¨­å®š =====
TIME_WINDOW_SIZE = 1000  # ãƒªãƒ³ã‚°ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚ºï¼ˆè¨˜æ†¶ã™ã‚‹è¦³æ¸¬å€¤ã®æ•°ï¼‰

# å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã€å€‹åˆ¥å®šæ•°ã‚‚ä¿æŒ
BKB_CONFIDENCE_K = BKB_CONFIG.confidence_k

# ===== æ™‚é–“çª“å­¦ç¿’ç”¨ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆæ—¢å­˜ã®maxæ‰‹æ³•ã¨åŒã˜ï¼‰=====
BKB_EVAPORATION_RATE = 0.999  # BKBå€¤ã®æ®ç™ºç‡ï¼ˆæ—¢å­˜ã®maxæ‰‹æ³•ã¨åŒã˜ï¼‰
ACHIEVEMENT_BONUS = 1.5  # BKBã‚’æ›´æ–°ã—ãŸå ´åˆã®å ±é…¬ãƒœãƒ¼ãƒŠã‚¹ä¿‚æ•°ï¼ˆæ—¢å­˜ã®maxæ‰‹æ³•ã¨åŒã˜ï¼‰
PENALTY_FACTOR = (
    0.5 if USE_TIME_WINDOW_LEARNING else BKB_CONFIG.penalty_factor
)  # æ™‚é–“çª“å­¦ç¿’ã®å ´åˆã¯æ—¢å­˜ã®maxæ‰‹æ³•ã¨åŒã˜

# ===== å‹•çš„å¸¯åŸŸå¤‰å‹•ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆAR(1)ãƒ¢ãƒ‡ãƒ«ï¼‰ =====
# å¸¯åŸŸå¤‰å‹•ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ bandwidth_fluctuation_config.py ã§ç®¡ç†


class Ant:
    def __init__(
        self, current: int, destination: int, route: list[int], width: list[int]
    ):
        self.current = current
        self.destination = destination
        self.route = route
        self.width = width

    def __repr__(self):
        return (
            f"Ant(current={self.current}, destination={self.destination}, "
            f"route={self.route}, width={self.width})"
        )


def set_pheromone_min_max_by_degree_and_width(graph: nx.Graph) -> None:
    """
    ãƒãƒ¼ãƒ‰ã®éš£æ¥æ•°ã¨å¸¯åŸŸå¹…ã«åŸºã¥ã„ã¦
    ãƒ•ã‚§ãƒ­ãƒ¢ãƒ³ã®æœ€å°å€¤ã¨æœ€å¤§å€¤ã‚’åŒæ–¹å‘ã«è¨­å®š
    """
    for u, v in graph.edges():
        # ãƒãƒ¼ãƒ‰uã¨vã®éš£æ¥ãƒãƒ¼ãƒ‰æ•°ã‚’å–å¾—
        degree_u = len(list(graph.neighbors(u)))
        degree_v = len(list(graph.neighbors(v)))

        # ãƒ•ã‚§ãƒ­ãƒ¢ãƒ³æœ€å°å€¤ã‚’éš£æ¥ãƒãƒ¼ãƒ‰æ•°ã«åŸºã¥ã„ã¦è¨­å®š
        graph[u][v]["min_pheromone"] = MIN_F * 3 // degree_u
        graph[v][u]["min_pheromone"] = MIN_F * 3 // degree_v

        # å¸¯åŸŸå¹…ã«åŸºã¥ã„ã¦ãƒ•ã‚§ãƒ­ãƒ¢ãƒ³æœ€å¤§å€¤ã‚’è¨­å®š
        width_u_to_v = graph[u][v]["weight"]
        width_v_to_u = graph[v][u]["weight"]

        graph[u][v]["max_pheromone"] = width_u_to_v**5
        graph[v][u]["max_pheromone"] = width_v_to_u**5


VOLATILIZATION_MODE = 3


# BKBæ›´æ–°é–¢æ•°ã®ãƒ©ãƒƒãƒ‘ãƒ¼ï¼ˆè¤‡æ•°ã®å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰ã«å¯¾å¿œï¼‰
def _create_bkb_update_func():
    """BKBæ›´æ–°é–¢æ•°ã‚’ä½œæˆï¼ˆå­¦ç¿’ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ã¦åˆ†å²ï¼‰"""

    def bkb_update_func(
        graph: nx.Graph, node: int, bottleneck: float, generation: int
    ) -> None:
        if USE_TIME_WINDOW_LEARNING:
            update_node_bkb_time_window_max(
                graph, node, bottleneck, generation, time_window_size=TIME_WINDOW_SIZE
            )
        elif USE_MULTI_SCALE_LEARNING:
            update_node_bkb_multi_scale_max(
                graph,
                node,
                bottleneck,
                short_window=5,
                medium_window=20,
                long_window=100,
                short_alpha=0.7,
                medium_alpha=0.3,
                long_alpha=0.1,
            )
        elif USE_THREE_PHASE_LEARNING:
            update_node_bkb_three_phase(graph, node, bottleneck, BKB_CONFIG)
        elif USE_TWO_PHASE_LEARNING:
            from bkb_learning import update_node_bkb_two_phase

            update_node_bkb_two_phase(graph, node, bottleneck, BKB_CONFIG)
        else:
            # å¾“æ¥ã®å˜ä¸€EMAå­¦ç¿’ï¼ˆRFC 6298æº–æ‹ ï¼‰
            mean_prev = graph.nodes[node].get("ema_bkb")
            if mean_prev is None:
                graph.nodes[node]["ema_bkb"] = float(bottleneck)
                graph.nodes[node]["ema_bkb_var"] = float(bottleneck) / 2.0
            else:
                update_node_bkb_statistics(graph, node, float(bottleneck), BKB_CONFIG)

    return bkb_update_func


# ===== å®šæ•°Îµ-Greedyæ³• =====
def ant_next_node_const_epsilon(
    ant_list: list[Ant],
    graph: nx.Graph,
    ant_log: list[int],
    current_optimal_bottleneck: int,
    generation: int,
) -> None:
    """
    å›ºå®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿(Î±, Î², Îµ)ã‚’ç”¨ã„ãŸã€æœ€ã‚‚ã‚·ãƒ³ãƒ—ãƒ«ãªÎµ-Greedyæ³•ã§æ¬¡ã®ãƒãƒ¼ãƒ‰ã‚’æ±ºå®šã™ã‚‹ã€‚
    """
    for ant in reversed(ant_list):
        neighbors = list(graph.neighbors(ant.current))
        candidates = [n for n in neighbors if n not in ant.route]

        if not candidates:
            ant_list.remove(ant)
            ant_log.append(0)
            continue  # æ¬¡ã®ã‚¢ãƒªã®å‡¦ç†ã¸

        # ===== å®šæ•°Îµ-Greedyé¸æŠ =====
        if random.random() < EPSILON:
            # ã€æ¢ç´¢ã€‘Îµã®ç¢ºç‡ã§ã€é‡ã¿ã‚’ç„¡è¦–ã—ã¦ãƒ©ãƒ³ãƒ€ãƒ ã«æ¬¡ãƒãƒ¼ãƒ‰ã‚’é¸æŠ
            next_node = random.choice(candidates)
        else:
            # ã€æ´»ç”¨ã€‘1-Îµã®ç¢ºç‡ã§ã€ãƒ•ã‚§ãƒ­ãƒ¢ãƒ³ã¨å¸¯åŸŸå¹…ã«åŸºã¥ã„ã¦æ¬¡ãƒãƒ¼ãƒ‰ã‚’é¸æŠ
            pheromones = [graph[ant.current][n]["pheromone"] for n in candidates]
            widths = [graph[ant.current][n]["weight"] for n in candidates]

            # Î±ã¨Î²ã¯å›ºå®šå€¤ã‚’ä½¿ç”¨
            weight_pheromone = [p**ALPHA for p in pheromones]
            weight_width = [w**BETA for w in widths]
            weights = [p * w for p, w in zip(weight_pheromone, weight_width)]

            # é‡ã¿ãŒå…¨ã¦0ã®å ´åˆã‚„å€™è£œãŒãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            if not weights or sum(weights) == 0:
                next_node = random.choice(candidates)
            else:
                next_node = random.choices(candidates, weights=weights, k=1)[0]
        # =======================

        # --- antã®çŠ¶æ…‹æ›´æ–° ---
        next_edge_bandwidth = graph[ant.current][next_node]["weight"]
        ant.route.append(next_node)
        ant.width.append(next_edge_bandwidth)
        ant.current = next_node

        # --- ã‚´ãƒ¼ãƒ«åˆ¤å®š ---
        if ant.current == ant.destination:
            # â˜…â˜…â˜… å…±é€šãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ãŸãƒ•ã‚§ãƒ­ãƒ¢ãƒ³æ›´æ–° â˜…â˜…â˜…
            update_pheromone(
                ant,
                graph,
                generation,
                max_pheromone=MAX_F,
                achievement_bonus=ACHIEVEMENT_BONUS,
                bkb_update_func=_create_bkb_update_func(),
                pheromone_increase_func=None,  # ã‚·ãƒ³ãƒ—ãƒ«ç‰ˆã‚’ä½¿ç”¨
                observe_bandwidth_func=None,  # å¸¯åŸŸç›£è¦–ã¯æœªä½¿ç”¨
            )
            ant_log.append(1 if min(ant.width) >= current_optimal_bottleneck else 0)
            ant_list.remove(ant)
        elif len(ant.route) >= TTL:
            ant_log.append(0)
            ant_list.remove(ant)


def ba_graph(num_nodes: int, num_edges: int = 3, lb: int = 1, ub: int = 10) -> nx.Graph:
    """
    BarabÃ¡si-Albertãƒ¢ãƒ‡ãƒ«ã§ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆ
    - å„ãƒãƒ¼ãƒ‰ã«BKBçµ±è¨ˆå±æ€§ï¼ˆå¹³å‡ãƒ»åˆ†æ•£ï¼‰ã‚’åˆæœŸåŒ–
    - å„ã‚¨ãƒƒã‚¸ã«å¸¯åŸŸå¹…(weight)ç­‰ã‚’åˆæœŸåŒ–
    """
    graph = nx.barabasi_albert_graph(num_nodes, num_edges)

    # ===== BKBçµ±è¨ˆãƒ¢ãƒ‡ãƒ«ç”¨ã®å±æ€§ã‚’åˆæœŸåŒ– =====
    if USE_TIME_WINDOW_LEARNING:
        # æ™‚é–“çª“å­¦ç¿’ã®å ´åˆï¼šæ—¢å­˜ã®maxæ‰‹æ³•ã¨åŒã˜åˆæœŸåŒ–
        for node in graph.nodes():
            graph.nodes[node]["best_known_bottleneck"] = 0
    else:
        # çµ±è¨ˆçš„BKBå­¦ç¿’ã®å ´åˆï¼šå…±é€šãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä½¿ç”¨
        initialize_graph_nodes_for_bkb(graph)
    # =======================================================================

    for u, v in graph.edges():
        # ãƒªãƒ³ã‚¯ã®å¸¯åŸŸå¹…(weight)ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«è¨­å®š
        weight = random.randint(lb, ub) * 10
        graph[u][v]["weight"] = weight

        # åˆæœŸå¸¯åŸŸå¹…ã‚’ä¿å­˜ï¼ˆå¤‰å‹•ã®åŸºæº–å€¤ã¨ã—ã¦ä½¿ç”¨ï¼‰
        graph[u][v]["original_weight"] = weight

        # NOTE: local_min/max_bandwidth ã¯æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã¯ä½¿ã‚ãªããªã‚Šã¾ã™ãŒã€
        #       æ®µéšçš„ãªç§»è¡Œã®ãŸã‚ä¸€æ—¦æ®‹ã—ã¾ã™ã€‚
        graph[u][v]["local_min_bandwidth"] = weight
        graph[u][v]["local_max_bandwidth"] = weight

        # ãƒ•ã‚§ãƒ­ãƒ¢ãƒ³å€¤ã‚’åˆæœŸåŒ–
        graph[u][v]["pheromone"] = MIN_F
        graph[u][v]["max_pheromone"] = MAX_F
        graph[u][v]["min_pheromone"] = MIN_F

    return graph


def er_graph(
    num_nodes: int, edge_prob: float = 0.12, lb: int = 1, ub: int = 10
) -> nx.Graph:
    """
    ErdÅ‘sâ€“RÃ©nyi (ER)ãƒ¢ãƒ‡ãƒ«ã§ãƒ©ãƒ³ãƒ€ãƒ ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆ
    - å„ãƒãƒ¼ãƒ‰ã«BKBçµ±è¨ˆå±æ€§ï¼ˆå¹³å‡ãƒ»åˆ†æ•£ï¼‰ã‚’åˆæœŸåŒ–
    - å„ã‚¨ãƒƒã‚¸ã«å¸¯åŸŸå¹…(weight)ç­‰ã‚’åˆæœŸåŒ–
    edge_probã¯ã€BAãƒ¢ãƒ‡ãƒ«ã¨åŒç¨‹åº¦ã®ã‚¨ãƒƒã‚¸æ•°ã«ãªã‚‹ã‚ˆã†ã«èª¿æ•´ã—ã¦ãã ã•ã„ã€‚
    """
    graph = nx.erdos_renyi_graph(num_nodes, edge_prob)

    # BKBçµ±è¨ˆãƒ¢ãƒ‡ãƒ«ç”¨ã®å±æ€§ã‚’åˆæœŸåŒ–
    if USE_TIME_WINDOW_LEARNING:
        # æ™‚é–“çª“å­¦ç¿’ã®å ´åˆï¼šæ—¢å­˜ã®maxæ‰‹æ³•ã¨åŒã˜åˆæœŸåŒ–
        for node in graph.nodes():
            graph.nodes[node]["best_known_bottleneck"] = 0
    else:
        # çµ±è¨ˆçš„BKBå­¦ç¿’ã®å ´åˆï¼šå…±é€šãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä½¿ç”¨
        initialize_graph_nodes_for_bkb(graph)

    for u, v in graph.edges():
        weight = random.randint(lb, ub) * 10
        graph[u][v]["weight"] = weight
        graph[u][v]["local_min_bandwidth"] = weight
        graph[u][v]["local_max_bandwidth"] = weight
        graph[u][v]["pheromone"] = MIN_F
        graph[u][v]["max_pheromone"] = MAX_F
        graph[u][v]["min_pheromone"] = MIN_F

    return graph


def grid_graph(num_nodes: int, lb: int = 1, ub: int = 10) -> nx.Graph:
    """
    ã‚°ãƒªãƒƒãƒ‰ï¼ˆæ ¼å­ï¼‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ç”Ÿæˆ
    - num_nodesãŒå¹³æ–¹æ•°ã®å ´åˆã®ã¿å¯¾å¿œï¼ˆä¾‹: 49, 100ï¼‰
    - å„ãƒãƒ¼ãƒ‰ã«BKBçµ±è¨ˆå±æ€§ï¼ˆå¹³å‡ãƒ»åˆ†æ•£ï¼‰ã‚’åˆæœŸåŒ–
    - å„ã‚¨ãƒƒã‚¸ã«å¸¯åŸŸå¹…(weight)ç­‰ã‚’åˆæœŸåŒ–
    """
    import math

    side = int(math.sqrt(num_nodes))
    if side * side != num_nodes:
        raise ValueError("num_nodesã¯å¹³æ–¹æ•°ï¼ˆä¾‹: 49, 100ï¼‰ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™")
    graph = nx.grid_2d_graph(side, side)
    # ãƒãƒ¼ãƒ‰ã‚’intå‹ã«å¤‰æ›ï¼ˆ0, 1, ..., num_nodes-1ï¼‰
    mapping = {(i, j): i * side + j for i in range(side) for j in range(side)}
    graph = nx.relabel_nodes(graph, mapping)

    # BKBçµ±è¨ˆãƒ¢ãƒ‡ãƒ«ç”¨ã®å±æ€§ã‚’åˆæœŸåŒ–
    if USE_TIME_WINDOW_LEARNING:
        # æ™‚é–“çª“å­¦ç¿’ã®å ´åˆï¼šæ—¢å­˜ã®maxæ‰‹æ³•ã¨åŒã˜åˆæœŸåŒ–
        for node in graph.nodes():
            graph.nodes[node]["best_known_bottleneck"] = 0
    else:
        # çµ±è¨ˆçš„BKBå­¦ç¿’ã®å ´åˆï¼šå…±é€šãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä½¿ç”¨
        initialize_graph_nodes_for_bkb(graph)
    for u, v in graph.edges():
        weight = random.randint(lb, ub) * 10
        graph[u][v]["weight"] = weight
        graph[u][v]["local_min_bandwidth"] = weight
        graph[u][v]["local_max_bandwidth"] = weight
        graph[u][v]["pheromone"] = MIN_F
        graph[u][v]["max_pheromone"] = MAX_F
        graph[u][v]["min_pheromone"] = MIN_F
    return graph


# ------------------ ãƒ¡ã‚¤ãƒ³å‡¦ç† ------------------
if __name__ == "__main__":  # noqa: C901
    # ===== è¨­å®šæƒ…å ±ã®è¡¨ç¤º =====
    print("=" * 70)
    print("ğŸš€ BKBå­¦ç¿’è¨­å®š")
    if USE_TIME_WINDOW_LEARNING:
        learning_method = "ãƒªãƒ³ã‚°ãƒãƒƒãƒ•ã‚¡å­¦ç¿’ï¼ˆç›´è¿‘1000å€‹ã®è¦³æ¸¬å€¤ã®æœ€å¤§å€¤ã‚’è¨˜æ†¶ã€å¤–ã‚ŒãŸã‚‰å‰Šé™¤ + æ®ç™ºç‡0.999ï¼‰"
    elif USE_MULTI_SCALE_LEARNING:
        learning_method = "è¤‡æ•°ã‚¹ã‚±ãƒ¼ãƒ«å­¦ç¿’ï¼ˆçŸ­æœŸ5ä¸–ä»£ + ä¸­æœŸ20ä¸–ä»£ + é•·æœŸ100ä¸–ä»£ï¼‰"
    elif USE_THREE_PHASE_LEARNING:
        learning_method = f"ä¸‰æ®µéšå­¦ç¿’ï¼ˆè¶…çŸ­æœŸÎ±=0.95 + çŸ­æœŸÎ±=0.7 + é•·æœŸÎ±={BKB_CONFIG.mean_alpha:.4f}ï¼‰"
    elif USE_TWO_PHASE_LEARNING:
        learning_method = f"äºŒæ®µéšå­¦ç¿’ï¼ˆçŸ­æœŸÎ±=0.5 + é•·æœŸÎ±={BKB_CONFIG.mean_alpha:.4f}ï¼‰"
    else:
        learning_method = f"å˜ä¸€EMAå­¦ç¿’ï¼ˆÎ±={BKB_CONFIG.mean_alpha:.4f}ï¼‰"
    print(f"   å­¦ç¿’æ‰‹æ³•: {learning_method}")
    print(f"   å­¦ç¿’ç‡ï¼ˆåˆ†æ•£ï¼‰: Î² = {BKB_CONFIG.var_beta:.4f}")
    print(f"   ãƒœãƒ¼ãƒŠã‚¹ä¿‚æ•°: {BKB_CONFIG.achievement_bonus_base}x")
    print(f"   ãƒšãƒŠãƒ«ãƒ†ã‚£ä¿‚æ•°: {BKB_CONFIG.penalty_factor}")
    print(f"   å¸¯åŸŸæ›´æ–°é–“éš”: {BANDWIDTH_UPDATE_INTERVAL}ä¸–ä»£ã”ã¨")
    print("   â˜…å¤‰å‹•å­¦ç¿’æ´»ç”¨: ãƒ•ã‚§ãƒ­ãƒ¢ãƒ³ä»˜åŠ ãƒ»æ®ç™ºã«BKBçµ±è¨ˆã‚’åæ˜ â˜…")
    print("=" * 70)

    # ===== ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®åˆæœŸåŒ– =====
    import os

    log_filename = "./simulation_result/log_ant_available_bandwidth_rfc.csv"

    # â˜…â˜…â˜… è©³ç´°åˆ†æç”¨ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ« â˜…â˜…â˜…
    log_detailed_rfc = "./simulation_result/log_detailed_tracking_rfc.csv"

    for filename in [log_filename, log_detailed_rfc]:
        if os.path.exists(filename):
            os.remove(filename)
            print(f"æ—¢å­˜ã®ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ« '{filename}' ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚")

        with open(filename, "w", newline="") as f:
            if filename == log_detailed_rfc:
                # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’æ›¸ãè¾¼ã¿
                writer = csv.writer(f)
                writer.writerow(
                    [
                        "simulation",
                        "generation",
                        "optimal_bw",
                        "goal_ultra_short_bkb",
                        "goal_short_bkb",
                        "goal_long_bkb",
                        "goal_effective_bkb",
                        "goal_var",
                        "confidence",
                        "tracking_rate_ultra_short",
                        "tracking_rate_short",
                        "tracking_rate_effective",
                        "success_rate",
                    ]
                )
        print(f"ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ« '{filename}' ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸã€‚")
    print()

    # ===== å¤‰å‹•è¨­å®šã®è¡¨ç¤º =====
    print_fluctuation_settings()

    for sim in range(SIMULATIONS):
        # ===== ã‚·ãƒ³ãƒ—ãƒ«ãªå›ºå®šã‚¹ã‚¿ãƒ¼ãƒˆãƒ»ã‚´ãƒ¼ãƒ«è¨­å®š =====
        NUM_NODES = 100
        START_NODE = random.randint(0, NUM_NODES - 1)
        GOAL_NODE = random.choice([n for n in range(NUM_NODES) if n != START_NODE])

        print(f"ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ {sim+1}: ã‚¹ã‚¿ãƒ¼ãƒˆ {START_NODE}, ã‚´ãƒ¼ãƒ« {GOAL_NODE}")

        # ã‚°ãƒ©ãƒ•ã¯ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã”ã¨ã«ä¸€åº¦ã ã‘ç”Ÿæˆ
        # graph = grid_graph(num_nodes=NUM_NODES, lb=1, ub=10)
        # graph = er_graph(num_nodes=NUM_NODES, edge_prob=0.12, lb=1, ub=10)
        graph = ba_graph(num_nodes=NUM_NODES, num_edges=6, lb=1, ub=15)

        set_pheromone_min_max_by_degree_and_width(graph)

        # â˜…å¤‰å‹•ã‚¨ãƒƒã‚¸ã‚’é¸æŠ (è¨­å®šã«å¿œã˜ã¦è‡ªå‹•é¸æŠ)â˜…
        fluctuating_edges = select_fluctuating_edges(graph)

        # â˜…å¤‰å‹•å¯¾è±¡ã‚¨ãƒƒã‚¸ã®ã¿ AR(1)çŠ¶æ…‹ã‚’åˆæœŸåŒ–â˜…
        edge_states = initialize_ar1_states(graph, fluctuating_edges)

        # â˜…åˆå›ã®å¸¯åŸŸæ›´æ–°ã‚‚å¤‰å‹•å¯¾è±¡ã®ã¿ã«é©ç”¨ã•ã‚Œã‚‹â˜…
        update_available_bandwidth_ar1(graph, edge_states, 0)

        # å‹•çš„ç’°å¢ƒã§ã®åˆæœŸæœ€é©è§£ã®è¨ˆç®—ï¼ˆæ¯”è¼ƒç”¨ï¼‰
        try:
            initial_optimal = calculate_current_optimal_bottleneck(
                graph, START_NODE, GOAL_NODE
            )
            print(f"å‹•çš„ç’°å¢ƒã§ã®åˆæœŸæœ€é©ãƒœãƒˆãƒ«ãƒãƒƒã‚¯å¸¯åŸŸ: {initial_optimal}")
        except (nx.NetworkXNoPath, Exception):
            print("çµŒè·¯ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            continue

        ant_log: list[int] = []
        bandwidth_change_log: list[int] = []  # å¸¯åŸŸå¤‰å‹•ã®è¨˜éŒ²
        bandwidth_change_count = 0  # å¸¯åŸŸå¤‰å‹•ã®ç´¯è¨ˆå›æ•°

        for generation in range(GENERATION):
            # === AR(1)ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹å¸¯åŸŸå¤‰å‹• ===
            bandwidth_changed = update_available_bandwidth_ar1(
                graph, edge_states, generation
            )
            bandwidth_change_log.append(1 if bandwidth_changed else 0)
            if bandwidth_changed:
                bandwidth_change_count += 1

            # === æœ€é©è§£ã®å†è¨ˆç®— ===
            current_optimal = calculate_current_optimal_bottleneck(
                graph, START_NODE, GOAL_NODE
            )
            if current_optimal == 0:
                # çµŒè·¯ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                continue

            # å¸¯åŸŸå¤‰å‹•ãŒã‚ã£ãŸå ´åˆã¯é€šçŸ¥
            if bandwidth_changed and generation % 50 == 0:
                avg_utilization = sum(edge_states.values()) / len(edge_states)
                print(
                    f"ä¸–ä»£ {generation}: AR(1)å¸¯åŸŸå¤‰å‹•ç™ºç”Ÿ - "
                    f"æ–°ã—ã„æœ€é©å€¤: {current_optimal}, "
                    f"å¹³å‡åˆ©ç”¨ç‡: {avg_utilization:.3f}"
                )

            # === ã‚¢ãƒªã®æ¢ç´¢ ===
            ants = [
                Ant(START_NODE, GOAL_NODE, [START_NODE], []) for _ in range(ANT_NUM)
            ]

            temp_ant_list = list(ants)
            while temp_ant_list:
                ant_next_node_const_epsilon(
                    temp_ant_list, graph, ant_log, current_optimal, generation
                )

            # ãƒ•ã‚§ãƒ­ãƒ¢ãƒ³ã®æ®ç™º
            # â˜…â˜…â˜… å…±é€šãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ãŸãƒ•ã‚§ãƒ­ãƒ¢ãƒ³æ®ç™º â˜…â˜…â˜…
            volatilize_by_width(
                graph,
                volatilization_mode=VOLATILIZATION_MODE,
                base_evaporation_rate=V,
                penalty_factor=PENALTY_FACTOR,
                adaptive_rate_func=None,  # å¸¯åŸŸå¤‰å‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ã«åŸºã¥ãé©å¿œçš„æ®ç™ºã¯æœªä½¿ç”¨
            )
            # BKBå€¤ã®æ®ç™ºå‡¦ç†ï¼ˆå…±é€šãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä½¿ç”¨ï¼‰
            evaporate_bkb_values(
                graph, BKB_EVAPORATION_RATE, use_int_cast=USE_TIME_WINDOW_LEARNING
            )

            # â˜…â˜…â˜… è©³ç´°ãƒ­ã‚°è¨˜éŒ²ï¼ˆ10ä¸–ä»£ã”ã¨ï¼‰ â˜…â˜…â˜…
            if generation % 10 == 0:
                goal_ultra_short = float(
                    graph.nodes[GOAL_NODE].get("ultra_short_ema_bkb") or 0.0
                )
                goal_short = float(graph.nodes[GOAL_NODE].get("short_ema_bkb") or 0.0)
                goal_long = float(graph.nodes[GOAL_NODE].get("long_ema_bkb") or 0.0)
                goal_effective = float(graph.nodes[GOAL_NODE].get("ema_bkb") or 0.0)
                goal_var_log = float(graph.nodes[GOAL_NODE].get("ema_bkb_var") or 0.0)
                confidence_log = calculate_confidence(goal_effective, goal_var_log)

                tracking_ultra_short = (
                    goal_ultra_short / current_optimal
                    if current_optimal > 0 and goal_ultra_short
                    else 0
                )
                tracking_short = (
                    goal_short / current_optimal
                    if current_optimal > 0 and goal_short
                    else 0
                )
                tracking_effective = (
                    goal_effective / current_optimal
                    if current_optimal > 0 and goal_effective
                    else 0
                )
                recent_success = (
                    sum(ant_log[-10:]) / min(len(ant_log), 10) if ant_log else 0
                )

                with open(log_detailed_rfc, "a", newline="") as f:
                    writer = csv.writer(f)
                    writer.writerow(
                        [
                            sim + 1,
                            generation,
                            current_optimal,
                            goal_ultra_short,
                            goal_short,
                            goal_long,
                            goal_effective,
                            goal_var_log,
                            confidence_log,
                            tracking_ultra_short,
                            tracking_short,
                            tracking_effective,
                            recent_success,
                        ]
                    )

            # é€²æ—è¡¨ç¤º
            if generation % 100 == 0:
                recent_success_rate = (
                    sum(ant_log[-100:]) / min(len(ant_log), 100) if ant_log else 0
                )

                # ===== ç¢ºä¿¡åº¦ã®è¨ˆç®—ï¼ˆã‚´ãƒ¼ãƒ«ãƒãƒ¼ãƒ‰ã®çµ±è¨ˆï¼‰å…±é€šãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä½¿ç”¨ =====
                goal_ultra_short_disp = float(
                    graph.nodes[GOAL_NODE].get("ultra_short_ema_bkb") or 0.0
                )
                goal_short_disp = float(
                    graph.nodes[GOAL_NODE].get("short_ema_bkb") or 0.0
                )
                goal_long_disp = float(
                    graph.nodes[GOAL_NODE].get("long_ema_bkb") or 0.0
                )
                goal_mean = float(graph.nodes[GOAL_NODE].get("ema_bkb") or 0.0)
                goal_var = float(graph.nodes[GOAL_NODE].get("ema_bkb_var") or 0.0)

                confidence = calculate_confidence(goal_mean, goal_var)
                goal_mean_display = goal_mean

                if USE_THREE_PHASE_LEARNING:
                    bkb_display = (
                        f"ã‚´ãƒ¼ãƒ«BKB[è¶…çŸ­æœŸ={goal_ultra_short_disp:.1f}, "
                        f"çŸ­æœŸ={goal_short_disp:.1f}, é•·æœŸ={goal_long_disp:.1f}, "
                        f"å®ŸåŠ¹={goal_mean_display:.1f}]Mbps"
                    )
                elif USE_TWO_PHASE_LEARNING:
                    bkb_display = (
                        f"ã‚´ãƒ¼ãƒ«BKB[çŸ­æœŸ={goal_short_disp:.1f}, "
                        f"é•·æœŸ={goal_long_disp:.1f}, å®ŸåŠ¹={goal_mean_display:.1f}]Mbps"
                    )
                else:
                    bkb_display = f"ã‚´ãƒ¼ãƒ«å¹³å‡BKB = {goal_mean_display:.1f}Mbps"

                print(
                    f"ä¸–ä»£ {generation}: æˆåŠŸç‡ = {recent_success_rate:.3f}, "
                    f"æœ€é©å€¤ = {current_optimal}Mbps, "
                    f"{bkb_display}, "
                    f"ç¢ºä¿¡åº¦ = {confidence:.3f}"
                )

                # æœ€é©è§£ã®è©³ç´°å‡ºåŠ›
                try:
                    optimal_path = max_load_path(graph, START_NODE, GOAL_NODE)
                    print(f"  æœ€é©çµŒè·¯: {' -> '.join(map(str, optimal_path))}")
                    print(f"  æœ€é©çµŒè·¯ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯å¸¯åŸŸ: {current_optimal}Mbps")
                except nx.NetworkXNoPath:
                    print("  æœ€é©çµŒè·¯: çµŒè·¯ãªã—")

        # --- çµæœã®ä¿å­˜ ---
        with open(log_filename, "a", newline="") as f:
            writer = csv.writer(f)
            writer.writerow(ant_log)

        # æœ€çµ‚æˆåŠŸç‡ã®è¡¨ç¤º
        final_success_rate = sum(ant_log) / len(ant_log) if ant_log else 0

        # æœ€çµ‚ç¢ºä¿¡åº¦ã®è¨ˆç®—ï¼ˆå…±é€šãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä½¿ç”¨ï¼‰
        goal_ultra_short_final = float(
            graph.nodes[GOAL_NODE].get("ultra_short_ema_bkb") or 0.0
        )
        goal_short_final = float(graph.nodes[GOAL_NODE].get("short_ema_bkb") or 0.0)
        goal_long_final = float(graph.nodes[GOAL_NODE].get("long_ema_bkb") or 0.0)
        goal_mean_final = float(graph.nodes[GOAL_NODE].get("ema_bkb") or 0.0)
        goal_var_final = float(graph.nodes[GOAL_NODE].get("ema_bkb_var") or 0.0)

        confidence_final = calculate_confidence(goal_mean_final, goal_var_final)
        goal_mean_final_display = goal_mean_final

        print(
            f"âœ… ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ {sim+1}/{SIMULATIONS} å®Œäº† - "
            f"æˆåŠŸç‡: {final_success_rate:.3f}, "
            f"æœ€çµ‚ç¢ºä¿¡åº¦: {confidence_final:.3f}, "
            f"ã‚´ãƒ¼ãƒ«å¹³å‡BKB: {goal_mean_final_display:.1f}Mbps"
        )

    print(f"\nğŸ‰ å…¨{SIMULATIONS}å›ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†ï¼")
