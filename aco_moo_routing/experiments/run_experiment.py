"""
å®Ÿé¨“å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ

config.yamlã®è¨­å®šã«åŸºã¥ãã€ACOã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã—ã€ãƒ‘ãƒ¬ãƒ¼ãƒˆãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ã¨æ¯”è¼ƒè©•ä¾¡ã‚’è¡Œã„ã¾ã™ã€‚
"""

import csv
import random
import sys
from datetime import datetime
from pathlib import Path

import yaml

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / "src"))

from aco_routing.algorithms.aco_solver import ACOSolver
from aco_routing.algorithms.pareto_solver import ParetoSolver
from aco_routing.algorithms.single_objective_solver import (
    bottleneck_capacity,
    max_load_path,
)
from aco_routing.core.graph import RoutingGraph
from aco_routing.utils.metrics import MetricsCalculator
from aco_routing.utils.visualization import Visualizer


def load_config(config_path: Path) -> dict:
    """
    è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€

    Args:
        config_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

    Returns:
        è¨­å®šè¾æ›¸
    """
    with open(config_path, "r", encoding="utf-8") as f:
        config = yaml.safe_load(f)
    return config


def compute_optimal_solutions(
    config: dict, graph: RoutingGraph, start_node: int, goal_node: int
) -> list:
    """
    æœ€é©è§£ã‚’è¨ˆç®—ï¼ˆå˜ä¸€æœ€é©è§£ or ãƒ‘ãƒ¬ãƒ¼ãƒˆãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ï¼‰

    Args:
        config: è¨­å®šè¾æ›¸
        graph: ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚°ãƒ©ãƒ•
        start_node: é–‹å§‹ãƒãƒ¼ãƒ‰
        goal_node: ç›®çš„åœ°ãƒãƒ¼ãƒ‰

    Returns:
        æœ€é©è§£ã®ãƒªã‚¹ãƒˆ [(bandwidth, delay, hops), ...]
    """
    optimal_solutions = []

    # å¸¯åŸŸã®ã¿æœ€é©åŒ–ã®å ´åˆ
    if config["experiment"]["target_objectives"] == ["bandwidth"]:
        try:
            optimal_path = max_load_path(graph.graph, start_node, goal_node)
            optimal_bottleneck = bottleneck_capacity(graph.graph, optimal_path)
            optimal_solutions = [(optimal_bottleneck, 0.0, 0)]
            print(f"  Optimal Bottleneck: {optimal_bottleneck} Mbps")
        except Exception as e:
            print(f"  âš ï¸  Warning: Could not calculate optimal solution: {e}")

    # ãƒ‘ãƒ¬ãƒ¼ãƒˆæœ€é©åŒ–ã®å ´åˆ
    elif config["pareto"]["enabled"]:
        print("  Calculating Pareto Frontier (exact solution)...")
        pareto_solver = ParetoSolver(
            graph.graph, config["pareto"]["max_labels_per_node"]
        )
        try:
            pareto_frontier_with_paths = pareto_solver.find_pareto_frontier(
                start_node, goal_node
            )
            # çµŒè·¯æƒ…å ±ã‚’é™¤ã„ã¦çµ±ä¸€å½¢å¼ã«å¤‰æ›
            optimal_solutions = [
                (pf[0], pf[1], pf[2]) for pf in pareto_frontier_with_paths
            ]
            print(f"  Pareto Frontier: {len(optimal_solutions)} solutions found.")
            print("\n  Pareto Optimal Solutions:")
            for i, sol in enumerate(optimal_solutions, 1):
                bandwidth, delay, hops = sol
                print(
                    f"    Solution {i}: Bandwidth={bandwidth:.0f} Mbps, Delay={delay:.0f} ms, Hops={hops}"
                )
        except Exception as e:
            print(f"  Error calculating Pareto Frontier: {e}")

    return optimal_solutions


def run_single_simulation(
    config: dict,
    sim: int,
    num_simulations: int,
    generations: int,
    metrics_calculator: MetricsCalculator,
) -> tuple:
    """
    1å›ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ

    Args:
        config: è¨­å®šè¾æ›¸
        sim: ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç•ªå·ï¼ˆ0-indexedï¼‰
        num_simulations: ç·ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•°
        generations: ä¸–ä»£æ•°
        metrics_calculator: è©•ä¾¡æŒ‡æ¨™è¨ˆç®—ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ

    Returns:
        (ant_log, final_solutions, pdr, dr, hv, optimal_solutions)
    """
    print(f"\n{'='*80}")
    print(f"Simulation {sim + 1}/{num_simulations}")
    print(f"{'='*80}")

    # ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆ
    num_nodes = config["graph"]["num_nodes"]
    graph = RoutingGraph(num_nodes, config)

    # ã‚¹ã‚¿ãƒ¼ãƒˆã¨ã‚´ãƒ¼ãƒ«ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠ
    start_node = random.randint(0, num_nodes - 1)
    goal_node = random.choice([n for n in range(num_nodes) if n != start_node])
    print(f"Start: {start_node}, Goal: {goal_node}")

    # æœ€é©è§£ã‚’è¨ˆç®—
    optimal_solutions = compute_optimal_solutions(config, graph, start_node, goal_node)

    # ACOã‚’å®Ÿè¡Œ
    print("Running ACO...")
    aco_solver = ACOSolver(config, graph)
    results, ant_log = aco_solver.run(
        start_node,
        goal_node,
        generations,
        optimal_solutions=optimal_solutions,
        metrics_calculator=metrics_calculator,
    )

    # æœ€çµ‚ä¸–ä»£ã®ACOè§£ã‚’åé›†
    final_solutions = []
    for result in results[-100:]:  # æœ€å¾Œã®100ä¸–ä»£
        final_solutions.extend(result["solutions"])
    final_solutions = list(set(final_solutions))  # é‡è¤‡é™¤å»
    print(
        f"ACO Solutions (final 100 generations): {len(final_solutions)} unique solutions"
    )

    # è©•ä¾¡æŒ‡æ¨™ã‚’è¨ˆç®—
    pdr, dr, hv = None, None, None
    if optimal_solutions:
        pdr = metrics_calculator.calculate_pareto_discovery_rate(
            final_solutions, optimal_solutions
        )
        dr = metrics_calculator.calculate_dominance_rate(
            final_solutions, optimal_solutions
        )
        hv = metrics_calculator.calculate_hypervolume(final_solutions)

        print("\nMetrics:")
        print(f"  Discovery Rate: {pdr:.3f}")
        print(f"  Dominance Rate: {dr:.3f}")
        print(f"  Hypervolume: {hv:.3f}")

    # æœ€é©è§£åˆ°é”ç‡ã®è¡¨ç¤ºï¼ˆæœ€é©è§£ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ >= 0 ã®å‰²åˆï¼‰
    final_success_rate = (
        sum(1 for idx in ant_log if idx >= 0) / len(ant_log) if ant_log else 0
    )
    print(f"Optimal Solution Discovery Rate: {final_success_rate:.3f}")

    return ant_log, final_solutions, pdr, dr, hv, optimal_solutions


def save_and_visualize_results(
    config: dict,
    results_dir: Path,
    all_ant_logs: list,
    all_pareto_discovery_rates: list,
    all_dominance_rates: list,
    all_hypervolumes: list,
    all_optimal_solutions: list,
    visualizer: Visualizer,
) -> None:
    """
    çµæœã‚’é›†è¨ˆã—ã€å¯è¦–åŒ–ã™ã‚‹

    Args:
        config: è¨­å®šè¾æ›¸
        results_dir: çµæœå‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        all_ant_logs: å…¨ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®ant_logãƒªã‚¹ãƒˆ
        all_pareto_discovery_rates: å…¨ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®PDRãƒªã‚¹ãƒˆ
        all_dominance_rates: å…¨ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®DRãƒªã‚¹ãƒˆ
        all_hypervolumes: å…¨ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®HVãƒªã‚¹ãƒˆ
        all_optimal_solutions: å…¨ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®æœ€é©è§£ãƒªã‚¹ãƒˆ
        visualizer: Visualizerã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    """
    print(f"\n{'='*80}")
    print("Summary of All Simulations")
    print(f"{'='*80}")

    # ãƒ•ã‚¡ã‚¤ãƒ«åã®ã‚µãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’ç”Ÿæˆï¼ˆtarget_objectivesã‹ã‚‰ï¼‰
    target_objectives = config["experiment"]["target_objectives"]
    suffix = "_".join(
        target_objectives
    )  # ä¾‹: "bandwidth_delay" ã¾ãŸã¯ "bandwidth_delay_hops"

    # è©•ä¾¡æŒ‡æ¨™ã®å¹³å‡å€¤ã‚’è¨ˆç®—
    if all_pareto_discovery_rates:
        avg_pdr = sum(all_pareto_discovery_rates) / len(all_pareto_discovery_rates)
        avg_dr = sum(all_dominance_rates) / len(all_dominance_rates)
        avg_hv = sum(all_hypervolumes) / len(all_hypervolumes)

        print(f"Average Pareto Discovery Rate: {avg_pdr:.3f}")
        print(f"Average Dominance Rate: {avg_dr:.3f}")
        print(f"Average Hypervolume: {avg_hv:.3f}")

        # ã‚µãƒãƒªãƒ¼å¯è¦–åŒ–
        if config["output"]["save_graphs"]:
            metrics_summary = {
                "Pareto Discovery Rate": avg_pdr,
                "Dominance Rate": avg_dr,
            }
            # ãƒ•ã‚¡ã‚¤ãƒ«åã«ã‚µãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’è¿½åŠ 
            base_name = "metrics_summary.png"
            name_parts = base_name.rsplit(".", 1)
            filename = f"{name_parts[0]}_{suffix}.{name_parts[1]}"
            visualizer.plot_metrics_summary(
                metrics_summary,
                filename=filename,
            )

    # æœ€é©è§£é¸æŠç‡ã®é·ç§»ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆ
    if config["output"]["save_graphs"] and all_ant_logs:
        num_ants = config["experiment"]["num_ants"]
        # ãƒ•ã‚¡ã‚¤ãƒ«åã«ã‚µãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’è¿½åŠ 
        base_name = "optimal_selection_rate.svg"
        name_parts = base_name.rsplit(".", 1)
        filename = f"{name_parts[0]}_{suffix}.{name_parts[1]}"
        visualizer.plot_optimal_selection_rate(
            all_ant_logs,
            num_ants,
            filename=filename,
        )

        # ãƒ‘ãƒ¬ãƒ¼ãƒˆæœ€é©è§£ãŒè¤‡æ•°ã‚ã‚‹å ´åˆã€ç©ã¿ä¸Šã’æ£’ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆ
        # å„ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®æœ€é©è§£ãŒåŒã˜ã‹ã©ã†ã‹ã‚’ãƒã‚§ãƒƒã‚¯
        if all_optimal_solutions and len(all_optimal_solutions[0]) > 1:
            # å…¨ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§å…±é€šã®æœ€é©è§£ã‚’ä½¿ç”¨ï¼ˆæœ€åˆã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®æœ€é©è§£ï¼‰
            # æ³¨: å„ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§æœ€é©è§£ãŒç•°ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŒã€
            #     å¯è¦–åŒ–ã®ãŸã‚æœ€åˆã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®æœ€é©è§£ã‚’ä½¿ç”¨
            common_optimal_solutions = all_optimal_solutions[0]
            base_name_stacked = "optimal_solution_selection_stacked.svg"
            name_parts_stacked = base_name_stacked.rsplit(".", 1)
            filename_stacked = (
                f"{name_parts_stacked[0]}_{suffix}.{name_parts_stacked[1]}"
            )
            visualizer.plot_optimal_solution_selection_stacked(
                all_ant_logs,
                num_ants,
                common_optimal_solutions,
                filename=filename_stacked,
            )


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿé¨“ãƒ«ãƒ¼ãƒ—"""
    # ===== è¨­å®šèª­ã¿è¾¼ã¿ =====
    config_path = project_root / "config" / "config.yaml"
    config = load_config(config_path)

    print("=" * 80)
    print(f"Experiment: {config['experiment']['name']}")
    print(f"Target Objectives: {config['experiment']['target_objectives']}")
    print("=" * 80)

    # ===== å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ =====
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    results_dir = project_root / config["output"]["results_dir"] / timestamp
    results_dir.mkdir(parents=True, exist_ok=True)
    print(f"Results directory: {results_dir}\n")

    # ===== CSVãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®åˆæœŸåŒ– =====
    log_csv_path = results_dir / "log_ant_available_bandwidth.csv"
    if log_csv_path.exists():
        log_csv_path.unlink()
    log_csv_path.touch()

    # ===== å¯è¦–åŒ–ãƒ»è©•ä¾¡æŒ‡æ¨™ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®åˆæœŸåŒ– =====
    visualizer = Visualizer(results_dir)
    metrics_calculator = MetricsCalculator(
        config["pareto"]["reference_point"],
        config["experiment"]["target_objectives"],
    )

    # ===== ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ =====
    num_simulations = config["experiment"]["simulations"]
    generations = config["experiment"]["generations"]

    # çµæœã‚’ä¿å­˜ã™ã‚‹ãƒªã‚¹ãƒˆ
    all_pareto_discovery_rates = []
    all_dominance_rates = []
    all_hypervolumes = []
    all_ant_logs = []
    all_optimal_solutions = []

    for sim in range(num_simulations):
        # 1å›ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ
        ant_log, final_solutions, pdr, dr, hv, optimal_solutions = (
            run_single_simulation(
                config, sim, num_simulations, generations, metrics_calculator
            )
        )

        # CSVãƒ­ã‚°ã«æ›¸ãè¾¼ã¿
        with open(log_csv_path, "a", newline="") as f:
            writer = csv.writer(f)
            writer.writerow(ant_log)

        # çµæœã‚’ä¿å­˜
        all_ant_logs.append(ant_log)
        all_optimal_solutions.append(optimal_solutions)
        if pdr is not None:
            all_pareto_discovery_rates.append(pdr)
            all_dominance_rates.append(dr)
            all_hypervolumes.append(hv)

    # ===== çµæœã®é›†è¨ˆã¨å¯è¦–åŒ– =====
    save_and_visualize_results(
        config,
        results_dir,
        all_ant_logs,
        all_pareto_discovery_rates,
        all_dominance_rates,
        all_hypervolumes,
        all_optimal_solutions,
        visualizer,
    )

    print(f"\nâœ… Experiment completed! Results saved to: {results_dir}")
    print(f"ğŸ“Š CSV Log: {log_csv_path}")


if __name__ == "__main__":
    main()
