# System Knowledge vs Agent Behavior åˆ†æã‚¬ã‚¤ãƒ‰

## ğŸ¯ ç›®çš„

**ã€Œã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ç¢ºç‡çš„ã«æ¢ç´¢ã—ã¦ã„ã‚‹ãŸã‚æˆåŠŸç‡ãŒå¤‰å‹•ã™ã‚‹ãŒã€ã‚·ã‚¹ãƒ†ãƒ å†…éƒ¨ï¼ˆãƒ•ã‚§ãƒ­ãƒ¢ãƒ³åˆ†å¸ƒï¼‰ã¯æ—©æœŸã«ç¢ºå®Ÿã«æœ€é©è§£ã‚’å­¦ç¿’ã—ã¦ã„ã‚‹ã€**ã“ã¨ã‚’è¦–è¦šçš„ã«è¨¼æ˜ã™ã‚‹ã€‚

---

## ğŸ“Š ã‚°ãƒ©ãƒ•ã®æ§‹æˆ

### 2ã¤ã®ç³»åˆ—

#### 1. **Agent Behaviorï¼ˆé’ç ´ç·šï¼‰** - ç¢ºç‡çš„ãªæŒ™å‹•
- **ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹**: `generation_stats.csv`ã®`optimal_count / num_ants`
- **æ„å‘³**: å®Ÿéš›ã«ãã®ä¸–ä»£ã§æœ€é©è§£ã‚’é€šã£ãŸã‚¢ãƒªã®å‰²åˆ
- **ç‰¹æ€§**: 
  - Îµ=0.1ã®ãƒ©ãƒ³ãƒ€ãƒ æ¢ç´¢ã®å½±éŸ¿ã§å¤‰å‹•
  - 100%ã«ã¯åˆ°é”ã—ãªã„ï¼ˆæ„å›³çš„ãªæ¢ç´¢ã‚’ç¶™ç¶šï¼‰
  - æ¢ç´¢ã®å¤šæ§˜æ€§ã‚’ç¶­æŒ

#### 2. **System Knowledgeï¼ˆèµ¤å®Ÿç·šï¼‰** - æ±ºå®šè«–çš„ãªåæŸ
- **ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹**: `generation_stats.csv`ã®`interest_hit`
- **æ„å‘³**: ãƒ•ã‚§ãƒ­ãƒ¢ãƒ³æœ€å¤§ã®ã‚¨ãƒƒã‚¸ã ã‘ã‚’è²ªæ¬²ã«é¸ã‚“ã çµæœãŒæœ€é©è§£ã ã£ãŸã‹ï¼ˆ0 or 1ï¼‰
- **ç‰¹æ€§**:
  - æ—©æœŸã«100%ã«åæŸï¼ˆã‚·ã‚¹ãƒ†ãƒ ãŒæœ€é©è§£ã‚’ç‰¹å®šï¼‰
  - åæŸå¾Œã¯100%ã‚’ç¶­æŒï¼ˆçŸ¥è­˜ã®ç¢ºå®Ÿæ€§ï¼‰
  - æ¢ç´¢ã®å½±éŸ¿ã‚’å—ã‘ãªã„

---

## ğŸ” è«–æ–‡ã§ã®è­°è«–ã®å±•é–‹

### 1. èƒŒæ™¯ï¼ˆå•é¡Œæèµ·ï¼‰

> **Îµ-greedyæ³•ãªã©ã®ç¢ºç‡çš„æ¢ç´¢ã‚’ç”¨ã„ã‚‹å ´åˆã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æŒ™å‹•ï¼ˆé’ã„ç ´ç·šï¼‰ã ã‘ã‚’è¦‹ã¦ã„ã¦ã¯ã€ã‚·ã‚¹ãƒ†ãƒ ãŒã„ã¤æœ€é©è§£ã‚’å­¦ç¿’ã—çµ‚ãˆãŸã®ã‹æ­£ç¢ºã«åˆ¤æ–­ã§ããªã„ã€‚**

### 2. äº‹å®Ÿï¼ˆã‚°ãƒ©ãƒ•ã®è¦³å¯Ÿï¼‰

> **å›³6ã‚’è¦‹ã‚‹ã¨ã€é’ã„ç ´ç·šï¼ˆAgent Behaviorï¼‰ã¯æ¢ç´¢ã®å½±éŸ¿ã§ç´„80-90%ä»˜è¿‘ã§æŒ¯å‹•ã—ã¦ãŠã‚Šã€100%ã«ã¯åˆ°é”ã—ãªã„ã€‚ã—ã‹ã—ã€ãƒ•ã‚§ãƒ­ãƒ¢ãƒ³æœ€å¤§ã®ã‚¨ãƒƒã‚¸ã‚’è²ªæ¬²ã«é¸ã¶èµ¤ã„å®Ÿç·šï¼ˆSystem Knowledgeï¼‰ã«ç€ç›®ã™ã‚‹ã¨ã€ç´„112ä¸–ä»£ä»˜è¿‘ã§æœ€é©è§£åˆ°é”ç‡ãŒ1.0ï¼ˆ100%ï¼‰ã«å¼µã‚Šä»˜ã„ã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã€‚**

### 3. æ´å¯Ÿï¼ˆInsightï¼‰

> **ã“ã®ä¹–é›¢ã¯é‡è¦ã§ã‚ã‚‹ã€‚ã‚·ã‚¹ãƒ†ãƒ ã¯112ä¸–ä»£ã¨ã„ã†æ—©æœŸã®æ®µéšã§ã€å†…éƒ¨çš„ã«ã¯æœ€é©è§£ã‚’ã€å®Œå…¨ã«ç‰¹å®šã€ã—ã¦ã„ã‚‹ã€‚ãã‚Œä»¥é™ã®é’ç·šã®ã‚†ã‚‰ãã¯ã€çŸ¥è­˜ä¸è¶³ã«ã‚ˆã‚‹è¿·ã„ã§ã¯ãªãã€è§£ã‚’ç¢ºå®šã•ã›ãŸä¸Šã§ã€ã•ã‚‰ãªã‚‹ç’°å¢ƒå¤‰åŒ–ã«å‚™ãˆã¦æ„å›³çš„ã«è¡Œã£ã¦ã„ã‚‹æ¢ç´¢ï¼ˆMonitoringï¼‰ã®çµæœã§ã‚ã‚‹ã¨è§£é‡ˆã§ãã‚‹ã€‚**

### 4. çµè«–ï¼ˆå„ªä½æ€§ï¼‰

> **ã¤ã¾ã‚Šã€ææ¡ˆæ‰‹æ³•ã¯ã€æ¢ç´¢ã®å¤šæ§˜æ€§ï¼ˆBehaviorã®åˆ†æ•£ï¼‰ã€ã‚’ç¶­æŒã—ã¤ã¤ã€ã€çŸ¥è­˜ã®ç¢ºå®Ÿæ€§ï¼ˆKnowledgeã®åæŸï¼‰ã€ã‚’æ—©æœŸã«ç¢ºç«‹ã§ãã‚‹ã€ãƒ­ãƒã‚¹ãƒˆãªå­¦ç¿’ç‰¹æ€§ã‚’æŒã£ã¦ã„ã‚‹ã“ã¨ãŒå®Ÿè¨¼ã•ã‚ŒãŸã€‚**

---

## ğŸ’¡ æœŸå¾…ã•ã‚Œã‚‹çµæœ

### Strictåˆ¶ç´„ç’°å¢ƒï¼ˆ5msï¼‰
```
System Knowledge: ç´„20-30ä¸–ä»£ã§100%åæŸ
Agent Behavior:   ç´„60-70%ã§å®‰å®šï¼ˆæ¢ç´¢ã®å½±éŸ¿ï¼‰
åæŸä¸–ä»£:        éå¸¸ã«æ—©ã„ï¼ˆè§£ç©ºé–“ãŒç‹­ã„ï¼‰
```

### Manualç’°å¢ƒï¼ˆé™çš„ï¼‰
```
System Knowledge: ç´„100-150ä¸–ä»£ã§100%åæŸ
Agent Behavior:   ç´„80-85%ã§å®‰å®š
åæŸä¸–ä»£:        ä¸­ç¨‹åº¦
```

### Dynamicç’°å¢ƒï¼ˆå¸¯åŸŸå¤‰å‹•ï¼‰
```
System Knowledge: å¤‰å‹•ã«å¿œã˜ã¦95-100%ã§æ¨ç§»
Agent Behavior:   ç´„75-85%ã§æ¨ç§»ï¼ˆã‚ˆã‚Šå¤šãã®æ¢ç´¢ï¼‰
åæŸä¸–ä»£:        å¤‰å‹•ã«ã‚ˆã‚Šå†å­¦ç¿’ãŒç™ºç”Ÿ
```

---

## ğŸš€ å®Ÿè¡Œæ‰‹é †

### Step 1: å®Ÿé¨“ã‚’å®Ÿè¡Œï¼ˆsimulations: 100æ¨å¥¨ï¼‰

```bash
cd /Users/asaken_n47/Documents/aco/Ant-Colony-Optimization/aco_moo_routing

# config.yamlã‚’ç·¨é›†:
# - method: "proposed"
# - graph_type: "manual"ï¼ˆã¾ãŸã¯ä»–ã®ç’°å¢ƒï¼‰
# - simulations: 100  # è¤‡æ•°å›å®Ÿè¡Œã§çµ±è¨ˆçš„ã«æœ‰æ„ãªçµæœ
# - generations: 1000

python experiments/run_experiment.py
```

### Step 2: ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆ

#### å˜ä¸€ç’°å¢ƒã®åˆ†æ

```bash
# Manualç’°å¢ƒã®ä¾‹
python analysis/plot_knowledge_vs_behavior.py \
  --results-dir results/proposed/manual/bandwidth_only \
  --num-ants 10 \
  --output results/analysis/manual_knowledge_vs_behavior

# é…å»¶åˆ¶ç´„ç’°å¢ƒã®ä¾‹ï¼ˆUnique Optimalã‚’ä½¿ç”¨ï¼‰
python analysis/plot_knowledge_vs_behavior.py \
  --results-dir results/proposed/delay_constraint_10ms/delay_constraint \
  --num-ants 10 \
  --use-unique \
  --output results/analysis/delay_10ms_knowledge_vs_behavior
```

#### è¤‡æ•°ç’°å¢ƒã®æ¯”è¼ƒ

```bash
# Manual, Static, Dynamicã®3ç’°å¢ƒã‚’æ¯”è¼ƒ
python analysis/plot_knowledge_vs_behavior.py \
  --results-dirs \
    results/proposed/manual/bandwidth_only \
    results/proposed/static/bandwidth_only \
    results/proposed/bandwidth_fluctuation/bandwidth_only \
  --labels "Manual" "Static" "Dynamic" \
  --num-ants 10 \
  --output results/analysis/knowledge_vs_behavior_comparison
```

---

## ğŸ“ˆ ã‚°ãƒ©ãƒ•ã®è§£é‡ˆãƒã‚¤ãƒ³ãƒˆ

### 1. **åæŸä¸–ä»£ã®ç‰¹å®š**

èµ¤å®Ÿç·šãŒ95%ã‚’è¶…ãˆãŸä¸–ä»£ = ã‚·ã‚¹ãƒ†ãƒ ãŒæœ€é©è§£ã‚’å­¦ç¿’ã—ãŸä¸–ä»£

```
ä¾‹: Manualç’°å¢ƒã§112ä¸–ä»£
â†’ ã€Œææ¡ˆæ‰‹æ³•ã¯112ä¸–ä»£ã§æœ€é©è§£ã‚’ç‰¹å®šã—ãŸã€
```

### 2. **Agent Behaviorã¨System Knowledgeã®å·®**

```
System: 100%ï¼ˆå®Œå…¨ãªçŸ¥è­˜ï¼‰
Agent:  85%ï¼ˆÎµ=0.1ã®æ¢ç´¢ï¼‰
å·®:     15% = æ„å›³çš„ãªæ¢ç´¢ã®å‰²åˆ
```

### 3. **Dynamicç’°å¢ƒã§ã®é©å¿œæ€§**

```
å¸¯åŸŸå¤‰å‹•æ™‚: System KnowledgeãŒä¸€æ™‚çš„ã«ä½ä¸‹
â†’ å¤‰åŒ–ã‚’æ¤œçŸ¥ã—ã€å†å­¦ç¿’
â†’ æ•°ä¸–ä»£ã§å†åæŸ
```

---

## ğŸ“ generation_stats.csvã®åˆ—ã®èª¬æ˜

| åˆ—å | èª¬æ˜ | ç”¨é€” |
|------|------|------|
| generation | ä¸–ä»£ç•ªå· | Xè»¸ |
| optimal_count | æœ€é©è§£ã‚’ç™ºè¦‹ã—ãŸã‚¢ãƒªã®æ•° | Agent Behaviorï¼ˆAny Optimalï¼‰ |
| unique_optimal_count | ä¸€æ„ãªæœ€é©è§£ã‚’ç™ºè¦‹ã—ãŸã‚¢ãƒªã®æ•° | Agent Behaviorï¼ˆUnique Optimalï¼‰ |
| interest_hit | ãƒ•ã‚§ãƒ­ãƒ¢ãƒ³è²ªæ¬²è§£ãŒæœ€é©è§£ã ã£ãŸã‹ï¼ˆ0/1ï¼‰ | System Knowledge |
| num_ants_reached | ã‚´ãƒ¼ãƒ«ã«åˆ°é”ã—ãŸã‚¢ãƒªã®æ•° | å‚è€ƒæƒ…å ± |
| avg_bandwidth | å¹³å‡ãƒœãƒˆãƒ«ãƒãƒƒã‚¯å¸¯åŸŸ | å‚è€ƒæƒ…å ± |

---

## ğŸ“ ç†è«–çš„èƒŒæ™¯

### Îµ-Greedyæ³•ã®ç‰¹æ€§

```python
if random.random() < Îµ:  # 10%ã®ç¢ºç‡
    # æ¢ç´¢ï¼ˆExplorationï¼‰: ãƒ©ãƒ³ãƒ€ãƒ é¸æŠ
    next_node = random.choice(candidates)
else:  # 90%ã®ç¢ºç‡
    # æ´»ç”¨ï¼ˆExploitationï¼‰: ãƒ•ã‚§ãƒ­ãƒ¢ãƒ³ã¨ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ã§é¸æŠ
    next_node = probabilistic_selection(...)
```

**Agent BehaviorãŒ100%ã«ãªã‚‰ãªã„ç†ç”±**:
- 10%ã®ç¢ºç‡ã§ãƒ©ãƒ³ãƒ€ãƒ é¸æŠ
- 90%ã®ç¢ºç‡ã§ã‚‚ç¢ºç‡çš„é¸æŠï¼ˆå¿…ãšã—ã‚‚æœ€è‰¯ã‚’é¸ã¶ã¨ã¯é™ã‚‰ãªã„ï¼‰
- â†’ ç†è«–ä¸Šã®ä¸Šé™: ç´„90-95%

**System KnowledgeãŒ100%ã«ãªã‚‹ç†ç”±**:
- å®Œå…¨ã«è²ªæ¬²ï¼ˆGreedyï¼‰: ãƒ•ã‚§ãƒ­ãƒ¢ãƒ³æœ€å¤§ã®ã‚¨ãƒƒã‚¸ã‚’ç¢ºå®šçš„ã«é¸æŠ
- æ¢ç´¢ã®å½±éŸ¿ã‚’å—ã‘ãªã„
- ãƒ•ã‚§ãƒ­ãƒ¢ãƒ³åˆ†å¸ƒãŒæœ€é©è§£ã«åæŸã™ã‚Œã°ã€å¸¸ã«æœ€é©è§£ã‚’é¸æŠ

---

## ğŸ“š é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

1. **plot_knowledge_vs_behavior.py** - ã‚°ãƒ©ãƒ•ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
2. **compare_delay_constraint.py** - é…å»¶åˆ¶ç´„ç’°å¢ƒã®æ¯”è¼ƒ
3. **FINAL_FIX_SUMMARY.md** - å…¨ä¿®æ­£ã®ã¾ã¨ã‚

---

## ğŸ¯ è«–æ–‡ã§ã®æ´»ç”¨ä¾‹

### Figure 6ã®ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³

```latex
\begin{figure}[tb]
 \centering
 \includegraphics[width=\columnwidth]{figures/06_knowledge_vs_behavior.eps}
 \caption{Convergence of probabilistic agent behavior vs. deterministic system knowledge.
 The red solid line represents the selection rate of the optimal path using deterministic 
 routing (max-pheromone selection), indicating the system's internal knowledge. 
 The blue dashed line represents the actual selection rate of agents operating under 
 an Îµ-greedy policy (Îµ=0.1). The system achieves near-perfect knowledge convergence 
 at generation 112, while agents maintain exploration diversity with 85\% exploitation.}
 \label{fig:knowledge_vs_behavior}
\end{figure}
```

### æœ¬æ–‡ã§ã®è¨€åŠ

```latex
\subsection{ãƒ•ã‚§ãƒ­ãƒ¢ãƒ³åˆ†å¸ƒã«åŸºã¥ãå†…éƒ¨çŸ¥è­˜ã®åæŸ}

å›³\ref{fig:knowledge_vs_behavior}ã«ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ç¢ºç‡çš„æŒ™å‹•ã¨ã‚·ã‚¹ãƒ†ãƒ ã®æ±ºå®šè«–çš„çŸ¥è­˜ã®åæŸã‚’ç¤ºã™ã€‚
èµ¤ã„å®Ÿç·šï¼ˆSystem Knowledgeï¼‰ã¯ã€å„ä¸–ä»£ã§ãƒ•ã‚§ãƒ­ãƒ¢ãƒ³é‡ãŒæœ€å¤§ã®ã‚¨ãƒƒã‚¸ã®ã¿ã‚’è²ªæ¬²ã«é¸æŠã—ãŸå ´åˆã®
æœ€é©è§£åˆ°é”ç‡ã‚’è¡¨ã—ã€é’ã„ç ´ç·šï¼ˆAgent Behaviorï¼‰ã¯ã€å®Ÿéš›ã«Îµ-greedyæ³•ï¼ˆÎµ=0.1ï¼‰ã§æ¢ç´¢ã‚’è¡Œã£ãŸ
ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æœ€é©è§£åˆ°é”ç‡ã‚’è¡¨ã™ã€‚

å›³ã‹ã‚‰ã€System Knowledgeã¯ç´„112ä¸–ä»£ã§100\%ã«åˆ°é”ã—ã€ãã®å¾Œã‚‚ç¶­æŒã•ã‚Œã¦ã„ã‚‹ã€‚
ä¸€æ–¹ã€Agent Behaviorã¯ç´„85\%ä»˜è¿‘ã§å®‰å®šã—ã¦ãŠã‚Šã€100\%ã«ã¯åˆ°é”ã—ãªã„ã€‚
ã“ã®15\%ã®å·®ã¯ã€Îµ=0.1ã®ãƒ©ãƒ³ãƒ€ãƒ æ¢ç´¢ã¨ç¢ºç‡çš„é¸æŠã«ã‚ˆã‚‹æ„å›³çš„ãªæ¢ç´¢ã®çµæœã§ã‚ã‚‹ã€‚

ã“ã®çµæœã¯ã€ææ¡ˆæ‰‹æ³•ãŒæ—©æœŸã«ã‚·ã‚¹ãƒ†ãƒ å†…éƒ¨ã®çŸ¥è­˜ã‚’ç¢ºç«‹ã—ã¤ã¤ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æ¢ç´¢å¤šæ§˜æ€§ã‚’
ç¶­æŒã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚ã™ãªã‚ã¡ã€112ä¸–ä»£ä»¥é™ã®é’ç·šã®å¤‰å‹•ã¯çŸ¥è­˜ä¸è¶³ã«ã‚ˆã‚‹è¿·ã„ã§ã¯ãªãã€
ç¢ºç«‹ã•ã‚ŒãŸçŸ¥è­˜ã‚’åŸºã«ã€ç’°å¢ƒå¤‰åŒ–ã¸ã®é©å¿œã®ãŸã‚ã«æ„å›³çš„ã«è¡Œã£ã¦ã„ã‚‹æ¢ç´¢ï¼ˆMonitoringï¼‰ã®
çµæœã§ã‚ã‚‹ã¨è§£é‡ˆã§ãã‚‹ã€‚
```

---

## ğŸ§ª æ‹¡å¼µã‚¢ã‚¤ãƒ‡ã‚¢

### 1. åæŸä¸–ä»£ã®ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³è¿½åŠ 

ã‚°ãƒ©ãƒ•ã«åæŸä¸–ä»£ã‚’çŸ¢å°ã§ç¤ºã™ï¼š

```python
if conv_gen is not None:
    ax.annotate(
        f'Convergence\nat gen. {conv_gen}',
        xy=(conv_gen, 100),
        xytext=(conv_gen + 100, 90),
        arrowprops=dict(arrowstyle='->', lw=2, color='red'),
        fontsize=14,
        ha='left'
    )
```

### 2. ä¹–é›¢ç‡ã®æ™‚ç³»åˆ—è¡¨ç¤º

System Knowledgeã¨Agent Behaviorã®å·®ã‚’åˆ¥ã®ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆã§è¡¨ç¤ºï¼š

```python
fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 10))

# ax1: å…ƒã®ã‚°ãƒ©ãƒ•
# ax2: ä¹–é›¢ç‡ï¼ˆSystem - Agentï¼‰
divergence = [(s - a) * 100 for s, a in zip(system_mean, agent_mean)]
ax2.plot(generations, divergence, color='purple', linewidth=2)
ax2.set_ylabel("Knowledge-Behavior Gap [%]")
```

### 3. å‹•çš„ç’°å¢ƒã§ã®å†å­¦ç¿’ã®å¯è¦–åŒ–

å¸¯åŸŸå¤‰å‹•ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’ç¸¦ç·šã§è¡¨ç¤ºï¼š

```python
# å¸¯åŸŸå¤‰å‹•ãŒç™ºç”Ÿã—ãŸä¸–ä»£ã‚’å–å¾—ï¼ˆåˆ¥é€”ãƒ­ã‚°ã‹ã‚‰ï¼‰
bandwidth_change_gens = [100, 200, 300, ...]
for gen in bandwidth_change_gens:
    ax.axvline(x=gen, color='gray', linestyle=':', alpha=0.5)
```


