"""
System Knowledge vs Agent Behavior ã®æ¯”è¼ƒã‚°ãƒ©ãƒ•ç”Ÿæˆ

ã€ç›®çš„ã€‘
ã€Œã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯Îµ=0.1ã§ãƒ©ãƒ³ãƒ€ãƒ ã«å‹•ã„ã¦ã„ã‚‹ãŸã‚ã€è¦‹ã‹ã‘ä¸Šã®æ­£è§£ç‡ã¯ä½ã„ï¼ˆå¤‰å‹•ã™ã‚‹ï¼‰ãŒã€
ã‚·ã‚¹ãƒ†ãƒ å†…éƒ¨ï¼ˆãƒ•ã‚§ãƒ­ãƒ¢ãƒ³åˆ†å¸ƒï¼‰ã¯ã‚‚ã£ã¨æ—©ã„æ®µéšã§ã€ã‹ã¤ç¢ºå®Ÿã«æœ€é©è§£ã‚’å­¦ç¿’ã—çµ‚ãˆã¦ã„ã‚‹ã€
ã“ã¨ã‚’è¦–è¦šçš„ã«è¨¼æ˜ã™ã‚‹ã€‚

ã€ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã€‘
generation_stats.csv ã®ä»¥ä¸‹ã®åˆ—ã‚’ä½¿ç”¨:
- optimal_count: å®Ÿéš›ã«ãã®ä¸–ä»£ã§æœ€é©è§£ã‚’é€šã£ãŸã‚¢ãƒªã®æ•°ï¼ˆAgent Behaviorï¼‰
- interest_hit: ãƒ•ã‚§ãƒ­ãƒ¢ãƒ³è²ªæ¬²è§£ãŒæœ€é©è§£ã ã£ãŸã‹ï¼ˆ0 or 1ã€System Knowledgeï¼‰

ã€è«–æ–‡ã§ã®èª¬æ˜ã€‘
- Agent Behaviorï¼ˆé’ç ´ç·šï¼‰: Îµ-greedyæ¢ç´¢ã«ã‚ˆã‚‹ç¢ºç‡çš„ãªæŒ™å‹•ï¼ˆæ¢ç´¢ã®å½±éŸ¿ã§å¤‰å‹•ï¼‰
- System Knowledgeï¼ˆèµ¤å®Ÿç·šï¼‰: ãƒ•ã‚§ãƒ­ãƒ¢ãƒ³åˆ†å¸ƒã®æ±ºå®šè«–çš„ãªåæŸï¼ˆã‚·ã‚¹ãƒ†ãƒ ã®å†…éƒ¨çŸ¥è­˜ï¼‰

ã€å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰ä¾‹ã€‘

# åŸºæœ¬çš„ãªä½¿ã„æ–¹ï¼ˆå˜ä¸€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœã‹ã‚‰ï¼‰
cd /Users/asaken_n47/Documents/aco/Ant-Colony-Optimization/aco_moo_routing

python analysis/plot_knowledge_vs_behavior.py \
  --results-dir results/proposed/static/bandwidth_only \
  --num-ants 10 \
  --output results/analysis/knowledge_vs_behavior

# è¤‡æ•°ç’°å¢ƒã®æ¯”è¼ƒï¼ˆmanual, static, bandwidth_fluctuationï¼‰
python analysis/plot_knowledge_vs_behavior.py \
  --results-dirs \
    results/proposed/manual/bandwidth_only \
    results/proposed/static/bandwidth_only \
    results/proposed/bandwidth_fluctuation/bandwidth_only \
  --labels "Manual" "Static" "Dynamic" \
  --num-ants 10 \
  --output results/analysis/knowledge_vs_behavior_comparison

# é…å»¶åˆ¶ç´„ç’°å¢ƒã§ã®æ¯”è¼ƒ
python analysis/plot_knowledge_vs_behavior.py \
  --results-dir results/proposed/delay_constraint_10ms/delay_constraint \
  --num-ants 10 \
  --use-unique \
  --output results/analysis/knowledge_vs_behavior_delay_10ms

ã€å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã€‘
- knowledge_vs_behavior.eps (è«–æ–‡ç”¨EPSå½¢å¼)
- knowledge_vs_behavior.svg (ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨SVGå½¢å¼)
- knowledge_vs_behavior.png (ãƒ—ãƒ¬ã‚¼ãƒ³ç”¨PNGå½¢å¼)

ã€è«–æ–‡ã§ã®ä½¿ç”¨ä¾‹ã€‘
Figure 6: Convergence of probabilistic agent behavior vs. deterministic system knowledge.
The red solid line represents the selection rate of the optimal path using deterministic 
routing (max-pheromone selection), indicating the system's internal knowledge. 
The blue dashed line represents the actual selection rate of agents operating under 
an Îµ-greedy policy (Îµ=0.1).
"""

import csv
import sys
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import matplotlib.pyplot as plt
import numpy as np

# ã‚°ãƒ©ãƒ•æç”»è¨­å®šï¼ˆè«–æ–‡å½¢å¼ï¼‰
FIGURE_WIDTH = 10
FIGURE_HEIGHT = 7
AXIS_LABEL_FONTSIZE = 24
TICK_LABEL_FONTSIZE = 18
LEGEND_FONTSIZE = 16
TITLE_FONTSIZE = 26


def load_generation_stats(csv_path: Path) -> List[Dict]:
    """
    generation_stats.csvã‚’èª­ã¿è¾¼ã‚€

    Args:
        csv_path: CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

    Returns:
        ä¸–ä»£ã”ã¨ã®ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ
    """
    data = []
    with open(csv_path, "r") as f:
        reader = csv.DictReader(f)
        for row in reader:
            data.append(row)
    return data


def aggregate_by_generation(
    all_stats: List[List[Dict]], num_ants: int
) -> Tuple[List[float], List[float], List[float], List[float]]:
    """
    è¤‡æ•°ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®çµæœã‚’ä¸–ä»£ã”ã¨ã«é›†è¨ˆ

    Args:
        all_stats: å…¨ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®generation_stats
        num_ants: 1ä¸–ä»£ã‚ãŸã‚Šã®ã‚¢ãƒªæ•°

    Returns:
        (agent_behavior_mean, agent_behavior_sem,
         system_knowledge_mean, system_knowledge_sem)
    """
    # ä¸–ä»£æ•°ã‚’å–å¾—ï¼ˆæœ€åˆã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‹ã‚‰ï¼‰
    num_generations = len(all_stats[0]) if all_stats else 0

    agent_behavior_by_gen = [[] for _ in range(num_generations)]
    system_knowledge_by_gen = [[] for _ in range(num_generations)]

    for stats in all_stats:
        for gen_idx, row in enumerate(stats):
            if gen_idx >= num_generations:
                break

            # Agent Behavior: optimal_count / num_ants
            optimal_count = int(row.get("optimal_count", 0) or 0)
            agent_rate = optimal_count / num_ants if num_ants > 0 else 0.0
            agent_behavior_by_gen[gen_idx].append(agent_rate)

            # System Knowledge: interest_hit (0 or 1)
            interest_hit = int(row.get("interest_hit", 0) or 0)
            system_knowledge_by_gen[gen_idx].append(interest_hit)

    # å¹³å‡ã¨æ¨™æº–èª¤å·®ã‚’è¨ˆç®—
    agent_mean = []
    agent_sem = []
    system_mean = []
    system_sem = []

    for gen in range(num_generations):
        agent_values = agent_behavior_by_gen[gen]
        system_values = system_knowledge_by_gen[gen]

        if agent_values:
            agent_mean.append(np.mean(agent_values))
            agent_sem.append(np.std(agent_values) / np.sqrt(len(agent_values)))
        else:
            agent_mean.append(0.0)
            agent_sem.append(0.0)

        if system_values:
            system_mean.append(np.mean(system_values))
            system_sem.append(np.std(system_values) / np.sqrt(len(system_values)))
        else:
            system_mean.append(0.0)
            system_sem.append(0.0)

    return agent_mean, agent_sem, system_mean, system_sem


def plot_single_environment(
    agent_mean: List[float],
    agent_sem: List[float],
    system_mean: List[float],
    system_sem: List[float],
    output_base: Path,
    title: Optional[str] = None,
):
    """
    å˜ä¸€ç’°å¢ƒã®Knowledge vs Behaviorã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆ

    ã€ã‚°ãƒ©ãƒ•ã®æ§‹æˆã€‘
    - èµ¤å®Ÿç·šï¼ˆå¤ªç·šï¼‰: System Knowledgeï¼ˆãƒ•ã‚§ãƒ­ãƒ¢ãƒ³è²ªæ¬²è§£ãŒæœ€é©è§£ï¼‰
    - é’ç ´ç·š: Agent Behaviorï¼ˆå®Ÿéš›ã«æœ€é©è§£ã‚’é€šã£ãŸã‚¢ãƒªã®å‰²åˆï¼‰
    - è–„ã„å¸¯: æ¨™æº–èª¤å·®ï¼ˆè¤‡æ•°ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®ã°ã‚‰ã¤ãï¼‰

    ã€è«–æ–‡ã§ã®è§£é‡ˆã€‘
    - Systemã¯æ—©æœŸã«100%åæŸï¼ˆå†…éƒ¨çŸ¥è­˜ã®ç¢ºç«‹ï¼‰
    - Agentã¯Îµ=0.1ã®æ¢ç´¢ã§å¤‰å‹•ï¼ˆæ„å›³çš„ãªæ¢ç´¢ï¼‰
    - ä¹–é›¢ = ã€Œå­¦ç¿’æ¸ˆã¿ã ãŒæ¢ç´¢ã‚‚ç¶™ç¶šã€ã®è¨¼æ‹ 
    """
    fig, ax = plt.subplots(figsize=(FIGURE_WIDTH, FIGURE_HEIGHT))

    generations = list(range(len(agent_mean)))

    # Agent Behavior (Probabilistic) - é’ç ´ç·š
    ax.plot(
        generations,
        [v * 100 for v in agent_mean],  # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆè¡¨ç¤º
        label="Agent Behavior (Probabilistic, Îµ=0.1)",
        color="#1f77b4",  # é’
        linestyle="--",
        linewidth=2.5,
        alpha=0.9,
        marker="o",
        markevery=50,
        markersize=5,
    )
    # æ¨™æº–èª¤å·®ã®å¸¯
    ax.fill_between(
        generations,
        [(v - e) * 100 for v, e in zip(agent_mean, agent_sem)],
        [(v + e) * 100 for v, e in zip(agent_mean, agent_sem)],
        color="#1f77b4",
        alpha=0.15,
    )

    # System Knowledge (Deterministic) - èµ¤å®Ÿç·šï¼ˆå¤ªãå¼·èª¿ï¼‰
    ax.plot(
        generations,
        [v * 100 for v in system_mean],  # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆè¡¨ç¤º
        label="System Knowledge (Deterministic, Greedy)",
        color="#d62728",  # èµ¤
        linestyle="-",
        linewidth=3.5,
        alpha=1.0,
        marker="s",
        markevery=50,
        markersize=6,
    )
    # æ¨™æº–èª¤å·®ã®å¸¯
    ax.fill_between(
        generations,
        [(v - e) * 100 for v, e in zip(system_mean, system_sem)],
        [(v + e) * 100 for v, e in zip(system_mean, system_sem)],
        color="#d62728",
        alpha=0.15,
    )

    # ã‚°ãƒªãƒƒãƒ‰ï¼ˆè«–æ–‡ã§ã®è¦–èªæ€§å‘ä¸Šï¼‰
    ax.grid(True, which="major", linestyle=":", linewidth=0.8, alpha=0.4, color="gray")
    ax.grid(True, which="minor", linestyle=":", linewidth=0.4, alpha=0.2, color="gray")

    # è»¸ç¯„å›²ã¨ãƒ©ãƒ™ãƒ«
    ax.set_ylim(0, 105)
    ax.set_xlim(0, max(generations) if generations else 1000)
    ax.set_xlabel("Generation", fontsize=AXIS_LABEL_FONTSIZE, fontweight="bold")
    ax.set_ylabel(
        "Optimal Path Selection Rate [%]",
        fontsize=AXIS_LABEL_FONTSIZE,
        fontweight="bold",
    )

    # ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    if title:
        ax.set_title(title, fontsize=TITLE_FONTSIZE, fontweight="bold", pad=20)

    # å‡¡ä¾‹ï¼ˆå³ä¸‹ã«é…ç½®ã€æ ã‚ã‚Šï¼‰
    ax.legend(
        loc="lower right",
        fontsize=LEGEND_FONTSIZE,
        frameon=True,
        framealpha=0.95,
        edgecolor="black",
        fancybox=False,
    )

    # è»¸ã®è£…é£¾
    for spine in ax.spines.values():
        spine.set_color("black")
        spine.set_linewidth(1.5)

    ax.tick_params(
        axis="both",
        which="major",
        labelsize=TICK_LABEL_FONTSIZE,
        direction="out",
        length=6,
        width=1.5,
        color="black",
    )
    ax.tick_params(
        axis="both",
        which="minor",
        direction="out",
        length=3,
        width=1.0,
        color="black",
    )
    ax.minorticks_on()

    plt.tight_layout()

    # EPSå½¢å¼ï¼ˆè«–æ–‡æŠ•ç¨¿ç”¨ï¼‰ã€SVGå½¢å¼ï¼ˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨ï¼‰ã€PNGå½¢å¼ï¼ˆãƒ—ãƒ¬ã‚¼ãƒ³ç”¨ï¼‰ã§ä¿å­˜
    out_eps = output_base.with_suffix(".eps")
    out_svg = output_base.with_suffix(".svg")
    out_png = output_base.with_suffix(".png")

    plt.savefig(str(out_eps), format="eps", dpi=300, bbox_inches="tight")
    plt.savefig(str(out_svg), format="svg", bbox_inches="tight")
    plt.savefig(str(out_png), format="png", dpi=300, bbox_inches="tight")

    print(f"\nâœ… ã‚°ãƒ©ãƒ•ã‚’ä¿å­˜ã—ã¾ã—ãŸ:")
    print(f"   ğŸ“„ EPS: {out_eps}")
    print(f"   ğŸ–¼ï¸  SVG: {out_svg}")
    print(f"   ğŸ–¼ï¸  PNG: {out_png}")

    plt.close()


def plot_multiple_environments(
    all_data: Dict[str, Tuple[List[float], List[float], List[float], List[float]]],
    output_base: Path,
):
    """
    è¤‡æ•°ç’°å¢ƒã®Knowledge vs Behaviorã‚’1ã¤ã®ã‚°ãƒ©ãƒ•ã«é‡ã­ã¦è¡¨ç¤º

    Args:
        all_data: {ç’°å¢ƒå: (agent_mean, agent_sem, system_mean, system_sem)}
        output_base: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ™ãƒ¼ã‚¹å
    """
    fig, ax = plt.subplots(figsize=(FIGURE_WIDTH, FIGURE_HEIGHT))

    # ç’°å¢ƒã”ã¨ã®é…è‰²ï¼ˆOkabe-Itoãƒ‘ãƒ¬ãƒƒãƒˆï¼‰
    colors = {
        0: "#0072B2",  # é’
        1: "#E69F00",  # ã‚ªãƒ¬ãƒ³ã‚¸
        2: "#009E73",  # ç·‘
        3: "#CC79A7",  # ãƒ”ãƒ³ã‚¯
    }

    for idx, (env_name, (agent_mean, agent_sem, system_mean, system_sem)) in enumerate(
        all_data.items()
    ):
        generations = list(range(len(agent_mean)))
        color = colors.get(idx, "#000000")

        # Agent Behaviorï¼ˆç ´ç·šï¼‰
        ax.plot(
            generations,
            [v * 100 for v in agent_mean],
            label=f"{env_name} - Agent Behavior",
            color=color,
            linestyle="--",
            linewidth=2.0,
            alpha=0.8,
        )

        # System Knowledgeï¼ˆå®Ÿç·šï¼‰
        ax.plot(
            generations,
            [v * 100 for v in system_mean],
            label=f"{env_name} - System Knowledge",
            color=color,
            linestyle="-",
            linewidth=3.0,
            alpha=1.0,
        )

    # ã‚°ãƒªãƒƒãƒ‰
    ax.grid(True, which="major", linestyle=":", linewidth=0.8, alpha=0.4, color="gray")

    # è»¸è¨­å®š
    ax.set_ylim(0, 105)
    ax.set_xlim(left=0)
    ax.set_xlabel("Generation", fontsize=AXIS_LABEL_FONTSIZE, fontweight="bold")
    ax.set_ylabel(
        "Optimal Path Selection Rate [%]",
        fontsize=AXIS_LABEL_FONTSIZE,
        fontweight="bold",
    )

    # å‡¡ä¾‹
    ax.legend(
        loc="lower right",
        fontsize=LEGEND_FONTSIZE - 2,
        frameon=True,
        framealpha=0.95,
        edgecolor="black",
        ncol=1,
    )

    # è»¸ã®è£…é£¾
    for spine in ax.spines.values():
        spine.set_color("black")
        spine.set_linewidth(1.5)

    ax.tick_params(
        axis="both",
        which="major",
        labelsize=TICK_LABEL_FONTSIZE,
        direction="out",
        length=6,
        width=1.5,
    )
    ax.minorticks_on()

    plt.tight_layout()

    # ä¿å­˜
    out_eps = output_base.with_suffix(".eps")
    out_svg = output_base.with_suffix(".svg")
    out_png = output_base.with_suffix(".png")

    plt.savefig(str(out_eps), format="eps", dpi=300, bbox_inches="tight")
    plt.savefig(str(out_svg), format="svg", bbox_inches="tight")
    plt.savefig(str(out_png), format="png", dpi=300, bbox_inches="tight")

    print(f"\nâœ… è¤‡æ•°ç’°å¢ƒæ¯”è¼ƒã‚°ãƒ©ãƒ•ã‚’ä¿å­˜ã—ã¾ã—ãŸ:")
    print(f"   ğŸ“„ EPS: {out_eps}")
    print(f"   ğŸ–¼ï¸  SVG: {out_svg}")
    print(f"   ğŸ–¼ï¸  PNG: {out_png}")

    plt.close()


def calculate_convergence_generation(system_mean: List[float], threshold: float = 0.95):
    """
    System KnowledgeãŒé–¾å€¤ã‚’è¶…ãˆãŸä¸–ä»£ã‚’è¨ˆç®—

    Args:
        system_mean: System Knowledgeã®å¹³å‡å€¤ãƒªã‚¹ãƒˆ
        threshold: åæŸã¨ã¿ãªã™é–¾å€¤ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.95 = 95%ï¼‰

    Returns:
        åæŸä¸–ä»£ï¼ˆè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯Noneï¼‰
    """
    for gen, value in enumerate(system_mean):
        if value >= threshold:
            return gen
    return None


def main():
    """
    ãƒ¡ã‚¤ãƒ³é–¢æ•°

    ã€å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ã€‘
    1. config.yamlã§å®Ÿé¨“ã‚’å®Ÿè¡Œï¼ˆsimulations: 100æ¨å¥¨ï¼‰
       - method: "proposed"
       - ãƒ­ã‚°å‡ºåŠ›ã‚’æœ‰åŠ¹åŒ–

    2. generation_stats.csvãŒç”Ÿæˆã•ã‚Œã‚‹

    3. ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œã—ã¦ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆ

    ã€ç”Ÿæˆã•ã‚Œã‚‹ã‚°ãƒ©ãƒ•ã€‘
    - Figure 6: System Knowledge vs Agent Behavior
    - èµ¤å®Ÿç·š: ãƒ•ã‚§ãƒ­ãƒ¢ãƒ³åˆ†å¸ƒã®åæŸï¼ˆã‚·ã‚¹ãƒ†ãƒ ã®å†…éƒ¨çŸ¥è­˜ï¼‰
    - é’ç ´ç·š: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å®Ÿéš›ã®æŒ™å‹•ï¼ˆÎµ-greedyæ¢ç´¢ï¼‰

    ã€è«–æ–‡ã§ã®è­°è«–ã€‘
    - ã€Œã‚·ã‚¹ãƒ†ãƒ ã¯ç´„Xä¸–ä»£ã§æœ€é©è§£ã‚’å®Œå…¨ã«ç‰¹å®šï¼ˆèµ¤ç·šãŒ100%ï¼‰ã€
    - ã€Œãã‚Œä»¥é™ã®é’ç·šã®å¤‰å‹•ã¯ã€æ¢ç´¢ç¶™ç¶šã«ã‚ˆã‚‹ã‚‚ã®ï¼ˆçŸ¥è­˜ä¸è¶³ã§ã¯ãªã„ï¼‰ã€
    - ã€Œæ¢ç´¢ã®å¤šæ§˜æ€§ã¨çŸ¥è­˜ã®ç¢ºå®Ÿæ€§ã‚’ä¸¡ç«‹ã€
    """
    import argparse

    parser = argparse.ArgumentParser(
        description="System Knowledge vs Agent Behavior ã®æ¯”è¼ƒã‚°ãƒ©ãƒ•ç”Ÿæˆï¼ˆè«–æ–‡å›³6ç”¨ï¼‰"
    )
    parser.add_argument(
        "--results-dir",
        type=str,
        default=None,
        help="å˜ä¸€ç’°å¢ƒã®çµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆgeneration_stats.csvãŒã‚ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼‰",
    )
    parser.add_argument(
        "--results-dirs",
        nargs="+",
        type=str,
        default=None,
        help="è¤‡æ•°ç’°å¢ƒã®çµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒªã‚¹ãƒˆï¼ˆè¤‡æ•°ç’°å¢ƒã‚’æ¯”è¼ƒã™ã‚‹å ´åˆï¼‰",
    )
    parser.add_argument(
        "--labels",
        nargs="+",
        type=str,
        default=None,
        help="å„ç’°å¢ƒã®ãƒ©ãƒ™ãƒ«ï¼ˆ--results-dirsã¨åŒã˜æ•°ã ã‘æŒ‡å®šï¼‰",
    )
    parser.add_argument(
        "--num-ants",
        type=int,
        required=True,
        help="1ä¸–ä»£ã‚ãŸã‚Šã®ã‚¢ãƒªæ•°ï¼ˆconfig.yamlã®num_antsã¨åŒã˜å€¤ï¼‰",
    )
    parser.add_argument(
        "--use-unique",
        action="store_true",
        help="unique_optimal_count ã‚’ä½¿ç”¨ï¼ˆé…å»¶åˆ¶ç´„ç’°å¢ƒç”¨ï¼‰",
    )
    parser.add_argument(
        "--output",
        type=str,
        default=None,
        help="å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆæœªæŒ‡å®šãªã‚‰ results/analysis/knowledge_vs_behaviorï¼‰",
    )

    args = parser.parse_args()

    # å˜ä¸€ç’°å¢ƒãƒ¢ãƒ¼ãƒ‰
    if args.results_dir:
        results_path = Path(args.results_dir)
        csv_path = results_path / "generation_stats.csv"

        if not csv_path.exists():
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {csv_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            sys.exit(1)

        # CSVã‚’èª­ã¿è¾¼ã¿
        print(f"ğŸ“‚ èª­ã¿è¾¼ã¿ä¸­: {csv_path}")
        stats = load_generation_stats(csv_path)

        # é›†è¨ˆï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã”ã¨ã«åˆ†å‰²ã•ã‚Œã¦ã„ã‚‹å‰æï¼‰
        # æ³¨: 1ã¤ã®CSVã«è¤‡æ•°ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãŒé€£çµã•ã‚Œã¦ã„ã‚‹å ´åˆã€
        #     ä¸–ä»£æ•°ã§åˆ†å‰²ã™ã‚‹å¿…è¦ãŒã‚ã‚‹
        # ã“ã“ã§ã¯ç°¡æ˜“çš„ã«ã€å…¨ãƒ‡ãƒ¼ã‚¿ã‚’1ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¨ã—ã¦æ‰±ã†
        all_stats = [stats]  # å¾Œã§è¤‡æ•°ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å¯¾å¿œã«æ‹¡å¼µå¯èƒ½

        agent_mean, agent_sem, system_mean, system_sem = aggregate_by_generation(
            all_stats, args.num_ants
        )

        # åæŸä¸–ä»£ã‚’è¨ˆç®—
        conv_gen = calculate_convergence_generation(system_mean, threshold=0.95)
        if conv_gen is not None:
            print(f"\nğŸ“Š System Knowledgeã®åæŸä¸–ä»£: {conv_gen}ä¸–ä»£ï¼ˆ95%åˆ°é”ï¼‰")
        else:
            print(f"\nğŸ“Š System Knowledgeã¯95%ã«æœªåˆ°é”")

        # ã‚°ãƒ©ãƒ•ç”Ÿæˆ
        if args.output:
            output_base = Path(args.output)
        else:
            output_base = Path("results/analysis/knowledge_vs_behavior")

        plot_single_environment(
            agent_mean, agent_sem, system_mean, system_sem, output_base
        )

    # è¤‡æ•°ç’°å¢ƒãƒ¢ãƒ¼ãƒ‰
    elif args.results_dirs:
        if not args.labels or len(args.labels) != len(args.results_dirs):
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: --labelsã¯--results-dirsã¨åŒã˜æ•°ã ã‘æŒ‡å®šã—ã¦ãã ã•ã„")
            sys.exit(1)

        all_env_data = {}

        for env_dir, label in zip(args.results_dirs, args.labels):
            csv_path = Path(env_dir) / "generation_stats.csv"

            if not csv_path.exists():
                print(f"âš ï¸ ã‚¹ã‚­ãƒƒãƒ—: {csv_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                continue

            print(f"ğŸ“‚ èª­ã¿è¾¼ã¿ä¸­: {csv_path} ({label})")
            stats = load_generation_stats(csv_path)
            all_stats = [stats]

            agent_mean, agent_sem, system_mean, system_sem = aggregate_by_generation(
                all_stats, args.num_ants
            )

            all_env_data[label] = (agent_mean, agent_sem, system_mean, system_sem)

        if not all_env_data:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            sys.exit(1)

        # ã‚°ãƒ©ãƒ•ç”Ÿæˆ
        if args.output:
            output_base = Path(args.output)
        else:
            output_base = Path("results/analysis/knowledge_vs_behavior_comparison")

        plot_multiple_environments(all_env_data, output_base)

    else:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: --results-dir ã¾ãŸã¯ --results-dirs ã‚’æŒ‡å®šã—ã¦ãã ã•ã„")
        parser.print_help()
        sys.exit(1)

    print(f"\nâœ… Analysis completed!")


if __name__ == "__main__":
    main()

