"""
çµ±åˆãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

4æ‰‹æ³•Ã—4ç’°å¢ƒã®å…¨16çµ„ã¿åˆã‚ã›ã§ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã—ã€ã‚¨ãƒ©ãƒ¼ãŒãªã„ã‹ç¢ºèªã—ã¾ã™ã€‚

ã€ãƒ†ã‚¹ãƒˆå¯¾è±¡ã€‘
- 4ã¤ã®æ‰‹æ³•ï¼š
  1. basic_aco_no_heuristic (å¾“æ¥æ‰‹æ³•1ï¼šåŸºæœ¬ACOã€Î²=0)
  2. basic_aco_with_heuristic (å¾“æ¥æ‰‹æ³•2ï¼šåŸºæœ¬ACOã€Î²=1)
  3. previous (å…ˆè¡Œç ”ç©¶ï¼šã‚¨ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã®å­¦ç¿’)
  4. proposed (ææ¡ˆæ‰‹æ³•ï¼šãƒãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®å­¦ç¿’)

- 4ã¤ã®ç’°å¢ƒï¼š
  1. manual (æ‰‹å‹•è¨­å®šãƒˆãƒãƒ­ã‚¸ï¼šæœ€é©çµŒè·¯ã‚’100Mbpsã«è¨­å®š)
  2. static (ãƒ©ãƒ³ãƒ€ãƒ ãƒˆãƒãƒ­ã‚¸ï¼šå…¨ãƒªãƒ³ã‚¯ãƒ©ãƒ³ãƒ€ãƒ )
  3. node_switching (ãƒãƒ¼ãƒ‰å¤‰å‹•ï¼šã‚¹ã‚¿ãƒ¼ãƒˆãƒãƒ¼ãƒ‰åˆ‡ã‚Šæ›¿ãˆ)
  4. bandwidth_fluctuation (å¸¯åŸŸå¤‰å‹•ï¼šAR1ãƒ¢ãƒ‡ãƒ«)
"""

import sys
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
aco_moo_root = Path(__file__).parent.parent
sys.path.insert(0, str(aco_moo_root / "src"))
sys.path.insert(0, str(aco_moo_root))

import yaml

# run_experimentã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆç›¸å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼‰
from experiments.run_experiment import main as run_experiment_main


def create_test_config(
    method: str,
    environment: str,
    generations: int = 10,
    simulations: int = 1,
    num_nodes: int = 20,  # ãƒ†ã‚¹ãƒˆç”¨ã«å°è¦æ¨¡ãªã‚°ãƒ©ãƒ•ã‚’ä½¿ç”¨
    num_edges: int = 3,  # ãƒ†ã‚¹ãƒˆç”¨ã«å°‘ãªã„ã‚¨ãƒƒã‚¸æ•°
) -> dict:
    """
    ãƒ†ã‚¹ãƒˆç”¨ã®è¨­å®šã‚’ç”Ÿæˆ

    Args:
        method: ACOæ‰‹æ³• ("basic_aco_no_heuristic", "basic_aco_with_heuristic", "previous", "proposed")
        environment: ç’°å¢ƒã‚¿ã‚¤ãƒ— ("manual", "static", "node_switching", "bandwidth_fluctuation")
        generations: ä¸–ä»£æ•°ï¼ˆãƒ†ã‚¹ãƒˆç”¨ã«çŸ­ãè¨­å®šï¼‰
        simulations: ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å›æ•°ï¼ˆãƒ†ã‚¹ãƒˆç”¨ã«1å›ï¼‰

    Returns:
        è¨­å®šè¾æ›¸
    """
    config = {
        "experiment": {
            "name": f"test_{method}_{environment}",
            "generations": generations,
            "num_ants": 10,
            "simulations": simulations,
            "target_objectives": ["bandwidth"],
            "delay_constraint": {"enabled": False, "max_delay": 10.0},
            "start_switching": {
                "enabled": environment == "node_switching",
                "switch_interval": 100,
                "start_nodes": [],
            },
        },
        "graph": {
            "num_nodes": num_nodes,  # ãƒ†ã‚¹ãƒˆç”¨ã«å°è¦æ¨¡
            "num_edges": num_edges,  # ãƒ†ã‚¹ãƒˆç”¨ã«å°‘ãªã„ã‚¨ãƒƒã‚¸æ•°
            "graph_type": "manual" if environment == "manual" else "barabasi_albert",
            "bandwidth_range": [10, 100],
            "delay_range": [1, 10],
            "fluctuation": {
                "enabled": environment == "bandwidth_fluctuation",
                "model": "ar1",
                "target_method": "hub",
                "target_percentage": 0.1,
                "update_interval": 1,
            },
        },
        "aco": {
            "method": method,
            "q_factor": 1.0,
            "alpha": 1.0,
            "beta_bandwidth": 0 if method == "basic_aco_no_heuristic" else 1.0,
            "beta_delay": 1.0,
            "beta_hops": 1.0,
            "epsilon": 0.1,
            "evaporation_rate": 0.02,
            "min_pheromone": 100,
            "max_pheromone": 1000000000,
            "ttl": 100,
            "learning": {
                "bkb_window_size": 100,
                "bonus_factor": 2.0,
                "penalty_factor": 0.5,
                "volatilization_mode": 3,
                "bkb_evaporation_rate": 0.001,
                "delay_tolerance": 5.0,
            },
        },
        "pareto": {
            "enabled": True,
            "max_labels_per_node": 1000,
            "reference_point": [0, 1000, 200],
        },
        "evaluation": {
            "metrics": [
                "pareto_discovery_rate",
                "dominance_rate",
                "hypervolume",
                "convergence_rate",
            ]
        },
        "output": {
            "save_results": True,
            "save_interval": 100,
            "save_graphs": False,  # ãƒ†ã‚¹ãƒˆæ™‚ã¯ã‚°ãƒ©ãƒ•ã‚’ä¿å­˜ã—ãªã„
            "results_dir": "results",
            "log_level": "INFO",
        },
    }
    return config


def run_test_with_config(method: str, environment: str, config: dict) -> bool:
    """
    1ã¤ã®çµ„ã¿åˆã‚ã›ã‚’ãƒ†ã‚¹ãƒˆï¼ˆè¨­å®šè¾æ›¸ã‚’ç›´æ¥å—ã‘å–ã‚‹ï¼‰

    Args:
        method: ACOæ‰‹æ³•
        environment: ç’°å¢ƒã‚¿ã‚¤ãƒ—
        config: è¨­å®šè¾æ›¸

    Returns:
        æˆåŠŸã—ãŸã‚‰Trueã€å¤±æ•—ã—ãŸã‚‰False
    """
    print(f"\n{'='*80}")
    print(f"Testing: Method={method}, Environment={environment}")
    print(f"{'='*80}")

    try:
        # å®Ÿé¨“ã‚’å®Ÿè¡Œï¼ˆè¨­å®šè¾æ›¸ã‚’ç›´æ¥æ¸¡ã™ï¼‰
        run_experiment_main(config_dict=config)

        print(f"âœ… Success: Method={method}, Environment={environment}")
        return True

    except Exception as e:
        print(f"âŒ Error: Method={method}, Environment={environment}")
        print(f"   Error message: {e}")
        import traceback

        traceback.print_exc()
        return False


def main():
    """å…¨çµ„ã¿åˆã‚ã›ã‚’ãƒ†ã‚¹ãƒˆ"""
    import argparse

    parser = argparse.ArgumentParser(description="Integration test for all method/environment combinations")
    parser.add_argument(
        "--quick",
        action="store_true",
        help="Quick test: only test first method and first environment",
    )
    parser.add_argument(
        "--generations",
        type=int,
        default=10,
        help="Number of generations for testing (default: 10)",
    )
    parser.add_argument(
        "--num-nodes",
        type=int,
        default=20,
        help="Number of nodes for testing (default: 20)",
    )
    args = parser.parse_args()

    methods = [
        "basic_aco_no_heuristic",
        "basic_aco_with_heuristic",
        "previous",
        "proposed",
    ]
    environments = [
        "manual",
        "static",
        "node_switching",
        "bandwidth_fluctuation",
    ]

    # ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ï¼šæœ€åˆã®çµ„ã¿åˆã‚ã›ã®ã¿
    if args.quick:
        methods = [methods[0]]
        environments = [environments[0]]
        print("âš ï¸  Quick test mode: Testing only first combination")

    results = {}
    total_tests = len(methods) * len(environments)
    passed_tests = 0
    failed_tests = 0

    print(f"\n{'='*80}")
    print(f"Integration Test: {total_tests} combinations")
    print(f"  Generations: {args.generations}")
    print(f"  Num nodes: {args.num_nodes}")
    print(f"{'='*80}")

    for method in methods:
        for environment in environments:
            key = f"{method}_{environment}"
            # ãƒ†ã‚¹ãƒˆç”¨è¨­å®šã‚’ç”Ÿæˆï¼ˆå¼•æ•°ã§æŒ‡å®šã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼‰
            config = create_test_config(
                method,
                environment,
                generations=args.generations,
                simulations=1,
                num_nodes=args.num_nodes,
                num_edges=3,
            )
            success = run_test_with_config(method, environment, config)
            results[key] = success
            if success:
                passed_tests += 1
            else:
                failed_tests += 1

    # çµæœã‚µãƒãƒªãƒ¼
    print(f"\n{'='*80}")
    print("Test Summary")
    print(f"{'='*80}")
    print(f"Total tests: {total_tests}")
    print(f"Passed: {passed_tests}")
    print(f"Failed: {failed_tests}")
    print(f"\nDetailed Results:")
    for key, success in results.items():
        status = "âœ… PASS" if success else "âŒ FAIL"
        print(f"  {status}: {key}")

    if failed_tests == 0:
        print(f"\nğŸ‰ All tests passed!")
        return 0
    else:
        print(f"\nâš ï¸  {failed_tests} test(s) failed.")
        return 1


if __name__ == "__main__":
    sys.exit(main())
