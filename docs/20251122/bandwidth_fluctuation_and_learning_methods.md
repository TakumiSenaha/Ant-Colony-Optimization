# 帯域変動と学習手法の定性的説明

## 1. 帯域変動の仕方

### 1.1 AR(1)モデルによる帯域変動

本シミュレーションでは、**AR(1)（1 次自己回帰）モデル**を用いて帯域変動を生成しています。

#### 変動の特徴

```python
利用率(t+1) = (1 - 0.95) × 平均利用率 + 0.95 × 利用率(t) + ノイズ
           = 0.05 × 0.4 + 0.95 × 利用率(t) + ノイズ
           = 0.02 + 0.95 × 利用率(t) + ノイズ
```

**定性的な特徴**:

1. **高い自己相関（φ = 0.95）**

   - 現在の値は、直前の値に 95%依存している
   - 急激な変化は起こりにくい（現実のネットワークトラフィックに近い）
   - 半減期: 約 14 世代（影響が半分になるまでの時間）

2. **平均回帰性**

   - 長期的には、利用率は平均値（40%）に収束する
   - 極端な状態（高帯域・低帯域）が長期間持続しない
   - 収束速度: 約 20 世代で 63%収束

3. **確率的変動（ノイズ）**

   - ノイズ項により、完全な予測は不可能
   - 標準偏差: 約 ±6.3%（95%信頼区間）
   - 探索の必要性を保証

4. **変動対象エッジ**
   - ハブノード（次数の高いノード）に接続するエッジのみが変動
   - 全エッジの 10%（`FLUCTUATION_PERCENTAGE = 0.1`）
   - 毎世代（`BANDWIDTH_UPDATE_INTERVAL = 1`）更新

#### 帯域幅への変換

```
可用帯域(t) = キャパシティ × (1 - 利用率(t))
```

利用率が高くなる → 可用帯域が低くなる
利用率が低くなる → 可用帯域が高くなる

---

## 2. 4 つの学習手法の定性的説明

### 共通のアーキテクチャ

すべての学習手法は以下の 3 つのステップで構成されています：

1. **観測（毎世代）**: 全エッジの帯域幅を観測して履歴に記録
2. **パターン学習（10 世代ごと）**: 履歴から変動パターンを学習
3. **予測・制御**: 学習したパターンに基づいて、予測的ヒューリスティックと適応的揮発を適用

---

### 手法 1: AR(1)予測 + 自己相関周期性検出

**一言で言うと**: **「自己回帰モデルによる時系列予測」** — TCP RTT 推定（RFC 6298）で採用されている手法。過去の値から現在の値を予測する線形回帰の時系列版。ネットワーク遅延推定や経済予測で広く使われる。

#### 学習の仕方

**周期性検出**:

- **自己相関ベース**: ラグ 1〜50 について自己相関係数を計算
- 相関係数が 0.5 を超える最も高いラグを周期として検出
- 例: ラグ 10 で相関係数 0.8 → 周期 10 世代と判定

**統計特性の学習**:

- 平均、分散、変動係数（CV）、AR(1)係数、トレンド（増加/減少/安定）を計算

#### 予測の仕方

**AR(1)予測**:

- AR(1)係数を最小二乗法で推定
- 予測式: `予測値 = 平均 + AR(1)係数 × (現在値 - 平均)`
- 「直前の値から平均への回帰」を仮定

**使用場面**:

- アリの経路選択時: 次世代の予測帯域幅をヒューリスティック値として使用
- 適応的揮発: 5 ステップ先まで予測して、予測値の変動性（CV）を計算

#### 揮発制御の仕方

**複数の調整ルールを組み合わせて適用**（すべてのルールが順番に乗算される）:

1. **予測変動性ベース**（`use_prediction_variability=True` の場合のみ）:

   - 5 ステップ先までの予測値の変動係数を計算
   - 予測変動が高い（CV > 0.3）→ 揮発率 × 0.90（探索促進）
   - 予測変動が中高（CV > 0.15）→ 揮発率 × 0.94
   - 予測変動が中（CV > 0.05）→ 揮発率 × 0.97
   - 予測変動が低い（CV ≤ 0.05）→ 揮発率 × 1.02（活用促進）

2. **変動係数（CV）ベース**（常に適用）:

   - 過去の観測値の変動係数を計算
   - CV が高い（変動が激しい、CV > 0.3）→ 揮発率 × 0.92（古い情報を早く忘れる）
   - CV が中高（CV > 0.15）→ 揮発率 × 0.96
   - CV が中（CV > 0.05）→ 揮発率 × 0.98
   - CV が低い（安定、CV ≤ 0.05）→ 揮発率 × 1.01（長期的な情報を保持）

3. **周期性ベース**（常に適用）:

   - 検出された周期と次の低帯域時期までの残り時間を計算
   - 次の低帯域時期が非常に近い（周期の 20%以内）→ 揮発率 × 0.88（その経路を避ける）
   - 次の低帯域時期が近い（周期の 30%以内）→ 揮発率 × 0.92
   - 次の低帯域時期がやや近い（周期の 50%以内）→ 揮発率 × 0.96

4. **トレンドベース**（常に適用）:

   - 減少傾向 → 揮発率 × 0.94（劣化している経路を避ける）
   - 増加傾向 → 揮発率 × 1.02（改善している経路を保持）
   - 安定 → 調整なし

5. **AR(1)係数ベース**（常に適用）:
   - AR(1)係数が高い（> 0.7）→ 揮発率 × 1.01（予測可能なので保持）
   - AR(1)係数が低い（< 0.3）→ 揮発率 × 0.98（予測困難なので早く忘れる）

**最終的な乗算係数は 0.80 〜 1.10 の範囲に制限される**

**特徴**:

- 生成モデル（AR(1)）と予測モデル（AR(1)）が一致 → 予測が有利になりやすい
- 定常過程を仮定した、シンプルで理解しやすい予測

---

### 手法 2: MA 予測 + 自己相関周期性検出

**一言で言うと**: **「移動平均による平滑化予測」** — 直近の観測値の単純平均を予測値とする。テクニカル分析（株価予測）や在庫管理でよく使われる手法。ノイズを平滑化し、計算量が最小。

#### 学習の仕方

**周期性検出**: 手法 1 と同じ（自己相関ベース）
**統計特性の学習**: 手法 1 と同じ

#### 予測の仕方

**MA（移動平均）予測**:

- 直近 5 個の観測値の単純平均を予測値とする
- 例: [80, 85, 82, 88, 90] → 予測値 = 85.0
- 計算量が最も少ない（O(1)）

**使用場面**:

- アリの経路選択時: 次世代の予測帯域幅（直近平均）を使用
- 適応的揮発: 5 ステップ先まで予測して変動性を計算

#### 揮発制御の仕方

手法 1 と同じ（予測変動性、CV、周期性ベース）

**特徴**:

- 最もシンプルで高速（計算量が少ない）
- ノイズに強いが、トレンドを考慮しない
- 生成モデル（AR(1)）と異なるため、より「未知の環境」に近い評価が可能

---

### 手法 3: EMA 予測 + 自己相関周期性検出

**一言で言うと**: **「指数平滑法による重み付き平均予測」** — より最近の観測値に指数関数的に大きな重みを付ける。Holt-Winters 法の基礎となる手法。需要予測や在庫管理システムで広く使われ、トレンドの変化に素早く反応する。

#### 学習の仕方

**周期性検出**: 手法 1 と同じ（自己相関ベース）
**統計特性の学習**: 手法 1 と同じ

#### 予測の仕方

**EMA（指数平滑法）予測**:

- より最近の観測値に大きな重みを付けて平滑化
- 計算: `EMA_t = 0.3 × 現在値 + 0.7 × EMA_{t-1}`
- 例: [80, 85, 82, 88, 90] → 予測値 ≈ 87.2

**使用場面**:

- アリの経路選択時: 次世代の予測帯域幅（最近値重視）を使用
- 適応的揮発: 5 ステップ先まで予測して変動性を計算

#### 揮発制御の仕方

手法 1 と同じ（5 つのルールを組み合わせて適用）

**特徴**:

- AR(1)より柔軟（最近の値に敏感）
- トレンドを追従しやすい
- 生成モデル（AR(1)）と異なるため、より「未知の環境」に近い評価が可能

---

### 手法 4: AR(1)予測 + ウェーブレット周期性検出

**一言で言うと**: **「ウェーブレット変換による時間-周波数解析」** — 信号処理や画像圧縮で使われるウェーブレット変換を時系列解析に応用。時間と周波数の両方で局所的にパターンを検出でき、過渡的・バースト的な周期性を捉えられる。研究コンペンディウム推奨の先進的手法。

#### 学習の仕方

**周期性検出**:

- **ウェーブレット変換**: Haar ウェーブレットの簡易版を使用
- 各周期候補（2〜50）について、時間と周波数で局在化したパターン強度を計算
- 周期 period での強度 = `Σ(history[i] - history[i-period])²`
- 強度が閾値（0.1）を超える最も強い周期を検出

**統計特性の学習**: 手法 1 と同じ

**特徴**:

- 自己相関より過渡的な周期性を検出しやすい
- バースト的な変動パターンにも対応可能
- 時間と周波数の両方を考慮した分析

#### 予測の仕方

**AR(1)予測**: 手法 1 と同じ

#### 揮発制御の仕方

手法 1 と同じ（5 つのルールを組み合わせて適用）

**特徴**:

- ウェーブレットによる周期性検出により、過渡的な変動パターンに対応
- 研究コンペンディウム推奨手法（Phase 2）
- AR(1)予測と組み合わせることで、予測精度と周期性検出の両立

---

## 3. 4 つの手法の比較まとめ

### 定性的な違い

| 手法                          | 周期性検出         | 予測手法   | 計算量   | 特徴                           |
| ----------------------------- | ------------------ | ---------- | -------- | ------------------------------ |
| **1. AR(1) + 自己相関**       | 自己相関           | AR(1)      | 中       | バランス型、モデル一致で有利   |
| **2. MA + 自己相関**          | 自己相関           | 移動平均   | **最小** | シンプル、高速、未知環境に近い |
| **3. EMA + 自己相関**         | 自己相関           | 指数平滑法 | 中       | 最近値に敏感、トレンド追従     |
| **4. AR(1) + ウェーブレット** | **ウェーブレット** | AR(1)      | 中       | 過渡的周期性に対応、研究推奨   |

### 揮発制御の共通ルール

すべての手法で以下の**5 つのルールを組み合わせて適用**（各ルールが順番に乗算される）：

1. **予測変動性ベース**（条件付き）: 5 ステップ先の予測値の変動性に基づく調整
2. **変動係数（CV）ベース**（常に適用）: 過去の観測値の変動係数に基づく調整
3. **周期性ベース**（常に適用）: 検出された周期と次の低帯域時期までの残り時間に基づく調整
4. **トレンドベース**（常に適用）: 増加/減少/安定の傾向に基づく調整
5. **AR(1)係数ベース**（常に適用）: 自己相関の強さに基づく調整

**最終的な乗算係数は 0.80 〜 1.10 の範囲に制限される**

### 評価の公平性に関する注意点

- **手法 1（AR(1)予測）**: 生成モデルが AR(1)のため、予測モデルと一致 → 「モデル既知」に近い状況
- **手法 2（MA 予測）**: 生成モデルと異なる → 「未知の環境」に近い評価
- **手法 3（EMA 予測）**: 生成モデルと異なる → 「未知の環境」に近い評価
- **手法 4（ウェーブレット）**: 周期性検出が優れているが、予測は AR(1) → 検出精度と予測精度のバランス

---

## 4. 学習プロセスの流れ

### 毎世代の処理

1. **帯域変動**: AR(1)モデルで選択されたエッジの帯域を更新
2. **帯域観測**: 全エッジの帯域を履歴に記録（リングバッファ、最大 100 個）
3. **アリの探索**: 予測的ヒューリスティックを使用して経路を選択
4. **フェロモン更新**: BKB を更新し、フェロモンを付加
5. **フェロモン揮発**: 適応的揮発率で揮発（帯域変動パターンに基づく）
6. **BKB 揮発**: BKB 値も揮発（忘却率 0.999）

### 10 世代ごとの処理

1. **パターン学習**: 全エッジの履歴から変動パターンを学習
   - 周期性検出（自己相関 or ウェーブレット）
   - 統計特性の計算（平均、分散、CV、AR(1)係数、トレンド）

---

## 5. まとめ

4 つの学習手法は、それぞれ異なる予測手法と周期性検出手法の組み合わせです。

- **手法 1**: 生成モデルと一致した予測（「既知の環境」での性能上限）
- **手法 2**: 最もシンプルで高速（計算量最小）
- **手法 3**: 最近の値に敏感（トレンド追従）
- **手法 4**: 過渡的周期性に対応（研究推奨）

すべての手法は、帯域変動パターンを学習し、予測的ヒューリスティックと適応的揮発によって動的環境に適応します。違いは、どのように「予測」し、どのように「周期性を検出」するかにあります。
